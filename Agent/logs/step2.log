--- RUN START: 단계 2/4: 수행 ---
CMD: python /home/jun/work/soongsil/Brainwash/main_inv.py --pretrained_model_add=/home/jun/work/soongsil/Brainwash/ewc_lamb_500000.0__model_type_resnet_dataset_split_cifar100_class_num_10_bs_16_lr_0.01_n_epochs_20__model_name_ResNet_task_num_9__seed_0_emb_fact_1_im_sz_32__last_task_9____optim_name_sgd.pkl --num_samples=128 --save_dir=/home/jun/work/soongsil/Brainwash/output --task_lst=0,1,2,3,4,5,6,7,8 --save_every=1000 --batch_reg --init_acc --n_iters=10000

/home/jun/work/soongsil/Brainwash/data_utils.py:109: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  y_train_task = torch.tensor(y_train_task)
/home/jun/work/soongsil/Brainwash/data_utils.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  y_tst_task = torch.tensor(y_tst_task)
/home/jun/work/soongsil/Brainwash/custom_optim.py:119: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha = 1) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1642.)
  exp_avg.mul_(beta1).add_(1 - beta1, grad)
Task order:  [array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]), array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]), array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]), array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49]), array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59]), array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69]), array([70, 71, 72, 73, 74, 75, 76, 77, 78, 79]), array([80, 81, 82, 83, 84, 85, 86, 87, 88, 89]), array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])]
init acc task 0: 57.4
init acc task 1: 57.9
init acc task 2: 68.5
init acc task 3: 59.3
init acc task 4: 63.0
init acc task 5: 64.60000000000001
init acc task 6: 63.1
init acc task 7: 61.9
init acc task 8: 62.0
task 0 iter 100 loss: 110573.40625 tv_loss: 0.47965335845947266 norm_loss: 0.9420932531356812 task_loss: 0.006079487968236208 loss_bn: 10.04965591430664
task 0 iter 200 loss: 59079.296875 tv_loss: 0.42076414823532104 norm_loss: 0.9068009853363037 task_loss: 0.003576300572603941 loss_bn: 4.961158275604248
task 0 iter 300 loss: 42379.125 tv_loss: 0.3924264907836914 norm_loss: 0.8837190270423889 task_loss: 0.002832698402926326 loss_bn: 3.321942090988159
task 0 iter 400 loss: 33881.89453125 tv_loss: 0.37428250908851624 norm_loss: 0.8722679615020752 task_loss: 0.0023065591230988503 loss_bn: 2.4891130924224854
task 0 iter 500 loss: 29123.8671875 tv_loss: 0.36079639196395874 norm_loss: 0.8666725158691406 task_loss: 0.0019337469711899757 loss_bn: 2.02276873588562
task 0 iter 600 loss: 26560.6328125 tv_loss: 0.3500918745994568 norm_loss: 0.8636447191238403 task_loss: 0.0017109308391809464 loss_bn: 1.771808385848999
task 0 iter 700 loss: 24306.8671875 tv_loss: 0.34104496240615845 norm_loss: 0.8618147969245911 task_loss: 0.0015212317230179906 loss_bn: 1.5502490997314453
task 0 iter 800 loss: 22383.0390625 tv_loss: 0.33308637142181396 norm_loss: 0.8606419563293457 task_loss: 0.0014009883161634207 loss_bn: 1.360321283340454
task 0 iter 900 loss: 21038.529296875 tv_loss: 0.32589828968048096 norm_loss: 0.8598001599311829 task_loss: 0.001280649215914309 loss_bn: 1.227987289428711
task 0 iter 1000 loss: 19956.880859375 tv_loss: 0.31934893131256104 norm_loss: 0.859129011631012 task_loss: 0.001189686474390328 loss_bn: 1.1214687824249268
task 0 iter 1100 loss: 18783.01171875 tv_loss: 0.3131431043148041 norm_loss: 0.8586130142211914 task_loss: 0.0011297807795926929 loss_bn: 1.0052589178085327
task 0 iter 1200 loss: 18117.28125 tv_loss: 0.3074333369731903 norm_loss: 0.8581675291061401 task_loss: 0.001041168230585754 loss_bn: 0.9400747418403625
task 0 iter 1300 loss: 16829.9765625 tv_loss: 0.3016654849052429 norm_loss: 0.857665479183197 task_loss: 0.000995576148852706 loss_bn: 0.8123596906661987
task 0 iter 1400 loss: 16853.88671875 tv_loss: 0.29649144411087036 norm_loss: 0.8572797775268555 task_loss: 0.0009458744316361845 loss_bn: 0.8156852126121521
task 0 iter 1500 loss: 17874.8359375 tv_loss: 0.2916942238807678 norm_loss: 0.8569729328155518 task_loss: 0.0009566117660142481 loss_bn: 0.9180275797843933
task 0 iter 1600 loss: 15914.060546875 tv_loss: 0.28767257928848267 norm_loss: 0.8567181825637817 task_loss: 0.0009006624459289014 loss_bn: 0.7228045463562012
task 0 iter 1700 loss: 18127.04296875 tv_loss: 0.28379756212234497 norm_loss: 0.8565213680267334 task_loss: 0.0008751862915232778 loss_bn: 0.9445930123329163
task 0 iter 1800 loss: 16898.30078125 tv_loss: 0.28052031993865967 norm_loss: 0.8563587665557861 task_loss: 0.0008191808592528105 loss_bn: 0.8224744200706482
task 0 iter 1900 loss: 16943.298828125 tv_loss: 0.2766062617301941 norm_loss: 0.8560835123062134 task_loss: 0.0008221352472901344 loss_bn: 0.8272590041160583
task 0 iter 2000 loss: 15982.01171875 tv_loss: 0.27364975214004517 norm_loss: 0.8559602499008179 task_loss: 0.0007881464553065598 loss_bn: 0.7316229343414307
task 0 iter 2100 loss: 15680.181640625 tv_loss: 0.270743191242218 norm_loss: 0.8557870984077454 task_loss: 0.0007784696645103395 loss_bn: 0.7017389535903931
task 0 iter 2200 loss: 16206.9619140625 tv_loss: 0.2682150602340698 norm_loss: 0.8556315898895264 task_loss: 0.0007195055950433016 loss_bn: 0.7551873922348022
task 0 iter 2300 loss: 15591.986328125 tv_loss: 0.26558396220207214 norm_loss: 0.8554714918136597 task_loss: 0.0006960121681913733 loss_bn: 0.6941112875938416
task 0 iter 2400 loss: 16135.2314453125 tv_loss: 0.26282477378845215 norm_loss: 0.8552535176277161 task_loss: 0.0007304600439965725 loss_bn: 0.7483367919921875
task 0 iter 2500 loss: 14962.74609375 tv_loss: 0.2605326175689697 norm_loss: 0.8551393747329712 task_loss: 0.0007099270587787032 loss_bn: 0.6314306259155273
task 0 iter 2600 loss: 14163.216796875 tv_loss: 0.2583048343658447 norm_loss: 0.8550014495849609 task_loss: 0.0006651164148934186 loss_bn: 0.5520859956741333
task 0 iter 2700 loss: 14447.806640625 tv_loss: 0.25657016038894653 norm_loss: 0.8548867702484131 task_loss: 0.0006388973561115563 loss_bn: 0.5809392333030701
task 0 iter 2800 loss: 15109.244140625 tv_loss: 0.2541951537132263 norm_loss: 0.8547065854072571 task_loss: 0.0006579670589417219 loss_bn: 0.6470963358879089
task 0 iter 2900 loss: 14131.4619140625 tv_loss: 0.25210440158843994 norm_loss: 0.8545711636543274 task_loss: 0.0006115024443715811 loss_bn: 0.549938976764679
task 0 iter 3000 loss: 13943.90234375 tv_loss: 0.2502865493297577 norm_loss: 0.8544589877128601 task_loss: 0.0006359931430779397 loss_bn: 0.5310683846473694
task 0 iter 3100 loss: 14777.37109375 tv_loss: 0.24878057837486267 norm_loss: 0.8544535040855408 task_loss: 0.0006150978151708841 loss_bn: 0.6146447658538818
task 0 iter 3200 loss: 13393.203125 tv_loss: 0.24703505635261536 norm_loss: 0.8543317317962646 task_loss: 0.0005810873117297888 loss_bn: 0.4767072796821594
task 0 iter 3300 loss: 13767.8671875 tv_loss: 0.2452225387096405 norm_loss: 0.8542394638061523 task_loss: 0.0005904945428483188 loss_bn: 0.5141900777816772
task 0 iter 3400 loss: 13799.0478515625 tv_loss: 0.24401776492595673 norm_loss: 0.8541906476020813 task_loss: 0.0005741197383031249 loss_bn: 0.5175328254699707
task 0 iter 3500 loss: 14270.248046875 tv_loss: 0.24249045550823212 norm_loss: 0.8540804386138916 task_loss: 0.0005635976558551192 loss_bn: 0.5648835301399231
task 0 iter 3600 loss: 12815.048828125 tv_loss: 0.2411266565322876 norm_loss: 0.8540469408035278 task_loss: 0.0005514158401638269 loss_bn: 0.41953244805336
task 0 iter 3700 loss: 13718.54296875 tv_loss: 0.24025659263134003 norm_loss: 0.8540892004966736 task_loss: 0.0005481422413140535 loss_bn: 0.5098811388015747
task 0 iter 3800 loss: 13302.19921875 tv_loss: 0.23918192088603973 norm_loss: 0.8540529012680054 task_loss: 0.0005274503491818905 loss_bn: 0.46850064396858215
task 0 iter 3900 loss: 13124.33984375 tv_loss: 0.23791944980621338 norm_loss: 0.8540158867835999 task_loss: 0.0005158743006177247 loss_bn: 0.450880229473114
task 0 iter 4000 loss: 13747.287109375 tv_loss: 0.2369571328163147 norm_loss: 0.8539658784866333 task_loss: 0.0005147189949639142 loss_bn: 0.5132459402084351
task 0 iter 4100 loss: 13279.6611328125 tv_loss: 0.23579896986484528 norm_loss: 0.8539413213729858 task_loss: 0.0004977321368642151 loss_bn: 0.46668946743011475
task 0 iter 4200 loss: 13179.328125 tv_loss: 0.23500171303749084 norm_loss: 0.8539534211158752 task_loss: 0.0005102198920212686 loss_bn: 0.45652711391448975
task 0 iter 4300 loss: 13467.4609375 tv_loss: 0.23452112078666687 norm_loss: 0.8540076017379761 task_loss: 0.0004763728938996792 loss_bn: 0.4856295585632324
task 0 iter 4400 loss: 14184.767578125 tv_loss: 0.2337038516998291 norm_loss: 0.8540430068969727 task_loss: 0.0004840265028178692 loss_bn: 0.5572564601898193
task 0 iter 4500 loss: 12375.31640625 tv_loss: 0.23270462453365326 norm_loss: 0.8539934754371643 task_loss: 0.00046633402234874666 loss_bn: 0.37654775381088257
task 0 iter 4600 loss: 13778.47265625 tv_loss: 0.2320328801870346 norm_loss: 0.8539701104164124 task_loss: 0.00044412160059437156 loss_bn: 0.517115592956543
task 0 iter 4700 loss: 12563.0810546875 tv_loss: 0.23132407665252686 norm_loss: 0.8539627194404602 task_loss: 0.0004363964544609189 loss_bn: 0.3956681787967682
task 0 iter 4800 loss: 12841.755859375 tv_loss: 0.2304592728614807 norm_loss: 0.853945255279541 task_loss: 0.0004326618800405413 loss_bn: 0.4235990643501282
task 0 iter 4900 loss: 12116.318359375 tv_loss: 0.22989371418952942 norm_loss: 0.8539299964904785 task_loss: 0.0004233425424899906 loss_bn: 0.35116952657699585
task 0 iter 5000 loss: 13183.208984375 tv_loss: 0.22918514907360077 norm_loss: 0.8538730144500732 task_loss: 0.00043147726682946086 loss_bn: 0.457841157913208
task 0 iter 5100 loss: 9527.6044921875 tv_loss: 0.2290782928466797 norm_loss: 0.8538227081298828 task_loss: 0.0004123440303374082 loss_bn: 0.09252340346574783
task 0 iter 5200 loss: 9500.337890625 tv_loss: 0.2288709282875061 norm_loss: 0.8538006544113159 task_loss: 0.00040140573401004076 loss_bn: 0.08993037790060043
task 0 iter 5300 loss: 9487.146484375 tv_loss: 0.22869592905044556 norm_loss: 0.8537976741790771 task_loss: 0.00039213651325553656 loss_bn: 0.08870868384838104
task 0 iter 5400 loss: 9469.693359375 tv_loss: 0.22853848338127136 norm_loss: 0.8538031578063965 task_loss: 0.0003841285943053663 loss_bn: 0.08703950047492981
task 0 iter 5500 loss: 9459.0966796875 tv_loss: 0.22839012742042542 norm_loss: 0.8538110852241516 task_loss: 0.0003773718199227005 loss_bn: 0.08604089170694351
task 0 iter 5600 loss: 9448.203125 tv_loss: 0.2282496839761734 norm_loss: 0.8538193702697754 task_loss: 0.0003717777435667813 loss_bn: 0.08500068634748459
task 0 iter 5700 loss: 9445.033203125 tv_loss: 0.2281143069267273 norm_loss: 0.8538265824317932 task_loss: 0.00036686318344436586 loss_bn: 0.08472692966461182
task 0 iter 5800 loss: 9438.6298828125 tv_loss: 0.2279796600341797 norm_loss: 0.8538333177566528 task_loss: 0.00036205476499162614 loss_bn: 0.08412931859493256
task 0 iter 5900 loss: 9425.9912109375 tv_loss: 0.2278384566307068 norm_loss: 0.8538404703140259 task_loss: 0.0003560900513548404 loss_bn: 0.0829193964600563
task 0 iter 6000 loss: 9469.2646484375 tv_loss: 0.22765150666236877 norm_loss: 0.8538380861282349 task_loss: 0.0003472802054602653 loss_bn: 0.08733902126550674
task 0 iter 6100 loss: 9417.140625 tv_loss: 0.22749701142311096 norm_loss: 0.8538447618484497 task_loss: 0.00033843121491372585 loss_bn: 0.08221002668142319
task 0 iter 6200 loss: 9392.1552734375 tv_loss: 0.22735154628753662 norm_loss: 0.8538477420806885 task_loss: 0.0003321172553114593 loss_bn: 0.07977303862571716
task 0 iter 6300 loss: 9460.81640625 tv_loss: 0.2272111177444458 norm_loss: 0.853846549987793 task_loss: 0.00032902538077905774 loss_bn: 0.08667265623807907
task 0 iter 6400 loss: 9426.2373046875 tv_loss: 0.22705930471420288 norm_loss: 0.8538520336151123 task_loss: 0.00032274945988319814 loss_bn: 0.08327366411685944
task 0 iter 6500 loss: 9465.326171875 tv_loss: 0.22690850496292114 norm_loss: 0.8538498282432556 task_loss: 0.00031734592630527914 loss_bn: 0.08724027127027512
task 0 iter 6600 loss: 9439.220703125 tv_loss: 0.2267727255821228 norm_loss: 0.8538514375686646 task_loss: 0.0003131674893666059 loss_bn: 0.08467119187116623
task 0 iter 6700 loss: 9427.439453125 tv_loss: 0.22664570808410645 norm_loss: 0.8538517951965332 task_loss: 0.0003099294553976506 loss_bn: 0.08352647721767426
task 0 iter 6800 loss: 9420.162109375 tv_loss: 0.22652244567871094 norm_loss: 0.8538510203361511 task_loss: 0.0003073319385293871 loss_bn: 0.082826629281044
task 0 iter 6900 loss: 9409.375 tv_loss: 0.22640638053417206 norm_loss: 0.8538501262664795 task_loss: 0.0003048954240512103 loss_bn: 0.08177445083856583
task 0 iter 7000 loss: 9407.0263671875 tv_loss: 0.22629180550575256 norm_loss: 0.8538496494293213 task_loss: 0.0003030697407666594 loss_bn: 0.08155940473079681
task 0 iter 7100 loss: 9403.431640625 tv_loss: 0.22616983950138092 norm_loss: 0.8538422584533691 task_loss: 0.00029950664611533284 loss_bn: 0.08124416321516037
task 0 iter 7200 loss: 9394.7216796875 tv_loss: 0.22605851292610168 norm_loss: 0.8538429737091064 task_loss: 0.00029674055986106396 loss_bn: 0.08040118962526321
task 0 iter 7300 loss: 9389.6591796875 tv_loss: 0.22594556212425232 norm_loss: 0.8538429141044617 task_loss: 0.00029447631095536053 loss_bn: 0.07991884648799896
task 0 iter 7400 loss: 9372.181640625 tv_loss: 0.2258216291666031 norm_loss: 0.8538392782211304 task_loss: 0.0002918572863563895 loss_bn: 0.07820217311382294
task 0 iter 7500 loss: 9397.345703125 tv_loss: 0.22566010057926178 norm_loss: 0.8538269996643066 task_loss: 0.0002888108720071614 loss_bn: 0.08076286315917969
task 0 iter 7600 loss: 9362.421875 tv_loss: 0.22552822530269623 norm_loss: 0.8538250923156738 task_loss: 0.0002840364759322256 loss_bn: 0.07732150703668594
task 0 iter 7700 loss: 9408.40625 tv_loss: 0.22540225088596344 norm_loss: 0.8538235425949097 task_loss: 0.0002800879592541605 loss_bn: 0.0819622352719307
task 0 iter 7800 loss: 9517.6103515625 tv_loss: 0.2252943217754364 norm_loss: 0.8538154363632202 task_loss: 0.00027671936550177634 loss_bn: 0.09292551875114441
task 0 iter 7900 loss: 9433.22265625 tv_loss: 0.2251647710800171 norm_loss: 0.8538159132003784 task_loss: 0.00027420741389505565 loss_bn: 0.08451256901025772
task 0 iter 8000 loss: 9472.1240234375 tv_loss: 0.22504840791225433 norm_loss: 0.8538116216659546 task_loss: 0.00027191604021936655 loss_bn: 0.08843113481998444
task 0 iter 8100 loss: 9465.908203125 tv_loss: 0.2249280959367752 norm_loss: 0.8538028001785278 task_loss: 0.0002696517331060022 loss_bn: 0.0878421887755394
task 0 iter 8200 loss: 9448.26953125 tv_loss: 0.2248121052980423 norm_loss: 0.8537968397140503 task_loss: 0.00026768443058244884 loss_bn: 0.08610506355762482
task 0 iter 8300 loss: 9438.3046875 tv_loss: 0.22470396757125854 norm_loss: 0.8537914752960205 task_loss: 0.00026585860177874565 loss_bn: 0.08513329178094864
task 0 iter 8400 loss: 9438.255859375 tv_loss: 0.2245950549840927 norm_loss: 0.8537877798080444 task_loss: 0.00026437354972586036 loss_bn: 0.08514811098575592
task 0 iter 8500 loss: 9419.61328125 tv_loss: 0.22448351979255676 norm_loss: 0.8537819385528564 task_loss: 0.00026287176297046244 loss_bn: 0.08330589532852173
task 0 iter 8600 loss: 9422.2431640625 tv_loss: 0.22436651587486267 norm_loss: 0.8537733554840088 task_loss: 0.00026113344938494265 loss_bn: 0.08359599113464355
task 0 iter 8700 loss: 9381.2919921875 tv_loss: 0.22424694895744324 norm_loss: 0.8537701964378357 task_loss: 0.00025955805904231966 loss_bn: 0.07952088862657547
task 0 iter 8800 loss: 9387.6474609375 tv_loss: 0.22414937615394592 norm_loss: 0.853762149810791 task_loss: 0.00025688682217150927 loss_bn: 0.08019228279590607
task 0 iter 8900 loss: 9324.60546875 tv_loss: 0.22404101490974426 norm_loss: 0.8537558913230896 task_loss: 0.0002549073251429945 loss_bn: 0.07391518354415894
task 0 iter 9000 loss: 9334.125 tv_loss: 0.22392651438713074 norm_loss: 0.853748083114624 task_loss: 0.0002532155776862055 loss_bn: 0.07489306479692459
task 0 iter 9100 loss: 9346.2333984375 tv_loss: 0.22381633520126343 norm_loss: 0.8537405729293823 task_loss: 0.0002519847184885293 loss_bn: 0.07612480223178864
task 0 iter 9200 loss: 9366.4716796875 tv_loss: 0.2236625850200653 norm_loss: 0.8537244200706482 task_loss: 0.00025024075875990093 loss_bn: 0.07818368077278137
task 0 iter 9300 loss: 9329.720703125 tv_loss: 0.2235455960035324 norm_loss: 0.8537180423736572 task_loss: 0.00024714029859751463 loss_bn: 0.0745471641421318
task 0 iter 9400 loss: 9304.177734375 tv_loss: 0.2234380543231964 norm_loss: 0.8537132740020752 task_loss: 0.00024466452305205166 loss_bn: 0.07202345132827759
task 0 iter 9500 loss: 9300.7490234375 tv_loss: 0.22333097457885742 norm_loss: 0.8537066578865051 task_loss: 0.00024261987709905952 loss_bn: 0.07170876860618591
task 0 iter 9600 loss: 9465.0390625 tv_loss: 0.22323469817638397 norm_loss: 0.8536946773529053 task_loss: 0.00024134428531397134 loss_bn: 0.08816349506378174
task 0 iter 9700 loss: 9443.77734375 tv_loss: 0.22313234210014343 norm_loss: 0.8536887764930725 task_loss: 0.000239426241023466 loss_bn: 0.08606341481208801
task 0 iter 9800 loss: 9433.0869140625 tv_loss: 0.22302991151809692 norm_loss: 0.8536810874938965 task_loss: 0.0002381320227868855 loss_bn: 0.08501598984003067
task 0 iter 9900 loss: 9417.4169921875 tv_loss: 0.22293055057525635 norm_loss: 0.8536733984947205 task_loss: 0.00023698584118392318 loss_bn: 0.08346916735172272
task 0 iter 10000 loss: 9405.25 tv_loss: 0.22283527255058289 norm_loss: 0.8536660075187683 task_loss: 0.00023589457850903273 loss_bn: 0.08227167278528214
task 1 iter 100 loss: 124448.953125 tv_loss: 0.4921712279319763 norm_loss: 0.945105254650116 task_loss: 0.005238116718828678 loss_bn: 11.442487716674805
task 1 iter 200 loss: 63887.375 tv_loss: 0.4301762282848358 norm_loss: 0.9126667976379395 task_loss: 0.002968828659504652 loss_bn: 5.442080974578857
task 1 iter 300 loss: 45520.87109375 tv_loss: 0.3999553322792053 norm_loss: 0.8888534903526306 task_loss: 0.0023160644341260195 loss_bn: 3.636073589324951
task 1 iter 400 loss: 36077.33203125 tv_loss: 0.38058388233184814 norm_loss: 0.875578761100769 task_loss: 0.0019003014313057065 loss_bn: 2.709345579147339
task 1 iter 500 loss: 30487.943359375 tv_loss: 0.3661484122276306 norm_loss: 0.8687201738357544 task_loss: 0.0016051483107730746 loss_bn: 2.1603610515594482
task 1 iter 600 loss: 27001.9140625 tv_loss: 0.3548542559146881 norm_loss: 0.8650656342506409 task_loss: 0.001413527992554009 loss_bn: 1.8174420595169067
task 1 iter 700 loss: 24916.546875 tv_loss: 0.34535837173461914 norm_loss: 0.862897515296936 task_loss: 0.0012375981314107776 loss_bn: 1.6129274368286133
task 1 iter 800 loss: 23233.09765625 tv_loss: 0.33702272176742554 norm_loss: 0.8614999055862427 task_loss: 0.0011540165869519114 loss_bn: 1.4468995332717896
task 1 iter 900 loss: 21759.42578125 tv_loss: 0.3295136094093323 norm_loss: 0.8605327010154724 task_loss: 0.00106194952968508 loss_bn: 1.3014951944351196
task 1 iter 1000 loss: 20600.814453125 tv_loss: 0.32269716262817383 norm_loss: 0.8598182797431946 task_loss: 0.0009585292427800596 loss_bn: 1.187450885772705
task 1 iter 1100 loss: 20295.03125 tv_loss: 0.3160867989063263 norm_loss: 0.8591777086257935 task_loss: 0.0008854048210196197 loss_bn: 1.1583105325698853
task 1 iter 1200 loss: 21172.140625 tv_loss: 0.3099650740623474 norm_loss: 0.8586177825927734 task_loss: 0.0008753542206250131 loss_bn: 1.2467432022094727
task 1 iter 1300 loss: 19662.1484375 tv_loss: 0.30465710163116455 norm_loss: 0.8581660985946655 task_loss: 0.000836655090097338 loss_bn: 1.0966356992721558
task 1 iter 1400 loss: 18654.2265625 tv_loss: 0.299906849861145 norm_loss: 0.8578031063079834 task_loss: 0.0008048325544223189 loss_bn: 0.9965722560882568
task 1 iter 1500 loss: 17983.7578125 tv_loss: 0.29557403922080994 norm_loss: 0.8574475049972534 task_loss: 0.0007596350042149425 loss_bn: 0.9303761720657349
task 1 iter 1600 loss: 18513.61328125 tv_loss: 0.2913099527359009 norm_loss: 0.8572255373001099 task_loss: 0.0007243378204293549 loss_bn: 0.9839794039726257
task 1 iter 1700 loss: 17484.87109375 tv_loss: 0.2872704267501831 norm_loss: 0.856908917427063 task_loss: 0.0006866445764899254 loss_bn: 0.8818391561508179
task 1 iter 1800 loss: 17025.828125 tv_loss: 0.2836250960826874 norm_loss: 0.8566771745681763 task_loss: 0.0006612440338358283 loss_bn: 0.8364570140838623
task 1 iter 1900 loss: 17065.205078125 tv_loss: 0.27950698137283325 norm_loss: 0.8563410043716431 task_loss: 0.0006624417728744447 loss_bn: 0.8407599329948425
task 1 iter 2000 loss: 15854.009765625 tv_loss: 0.27615833282470703 norm_loss: 0.8561314344406128 task_loss: 0.0006337157101370394 loss_bn: 0.7201707363128662
task 1 iter 2100 loss: 15596.1796875 tv_loss: 0.27319127321243286 norm_loss: 0.8559743165969849 task_loss: 0.0005761035718023777 loss_bn: 0.6951506733894348
task 1 iter 2200 loss: 16272.279296875 tv_loss: 0.27032098174095154 norm_loss: 0.8558568358421326 task_loss: 0.0005757980979979038 loss_bn: 0.7629098892211914
task 1 iter 2300 loss: 15978.83984375 tv_loss: 0.2675316333770752 norm_loss: 0.8556816577911377 task_loss: 0.0005449916352517903 loss_bn: 0.7340772151947021
task 1 iter 2400 loss: 15249.869140625 tv_loss: 0.264687716960907 norm_loss: 0.855451226234436 task_loss: 0.0005606519407592714 loss_bn: 0.6612822413444519
task 1 iter 2500 loss: 15487.1328125 tv_loss: 0.2623714506626129 norm_loss: 0.8553358912467957 task_loss: 0.0005280306795611978 loss_bn: 0.6854733824729919
task 1 iter 2600 loss: 15550.7421875 tv_loss: 0.2599128484725952 norm_loss: 0.8551537990570068 task_loss: 0.0005013722693547606 loss_bn: 0.6923074722290039
task 1 iter 2700 loss: 14309.123046875 tv_loss: 0.2574494481086731 norm_loss: 0.8549567461013794 task_loss: 0.0004910818533971906 loss_bn: 0.5684702396392822
task 1 iter 2800 loss: 14107.74609375 tv_loss: 0.25536975264549255 norm_loss: 0.8548568487167358 task_loss: 0.0004900574567727745 loss_bn: 0.5484635233879089
task 1 iter 2900 loss: 13898.876953125 tv_loss: 0.2534680664539337 norm_loss: 0.854729413986206 task_loss: 0.0004674506199080497 loss_bn: 0.5279491543769836
task 1 iter 3000 loss: 13918.427734375 tv_loss: 0.251854807138443 norm_loss: 0.854651153087616 task_loss: 0.00047971680760383606 loss_bn: 0.5298759341239929
task 1 iter 3100 loss: 14805.41015625 tv_loss: 0.2500803470611572 norm_loss: 0.8545615673065186 task_loss: 0.0004523468960542232 loss_bn: 0.618955135345459
task 1 iter 3200 loss: 13967.119140625 tv_loss: 0.2481847107410431 norm_loss: 0.854422926902771 task_loss: 0.0004551284946501255 loss_bn: 0.5352558493614197
task 1 iter 3300 loss: 15598.8291015625 tv_loss: 0.24603527784347534 norm_loss: 0.8542636632919312 task_loss: 0.00044686722685582936 loss_bn: 0.6986902356147766
task 1 iter 3400 loss: 14306.884765625 tv_loss: 0.2445988655090332 norm_loss: 0.8541872501373291 task_loss: 0.00043707824079319835 loss_bn: 0.5696845054626465
task 1 iter 3500 loss: 13631.333984375 tv_loss: 0.24323606491088867 norm_loss: 0.8541668653488159 task_loss: 0.0004229589249007404 loss_bn: 0.5023045539855957
task 1 iter 3600 loss: 13785.70703125 tv_loss: 0.24176287651062012 norm_loss: 0.8541624546051025 task_loss: 0.00042732825386337936 loss_bn: 0.5177173018455505
task 1 iter 3700 loss: 13755.2724609375 tv_loss: 0.24042630195617676 norm_loss: 0.8540545701980591 task_loss: 0.00042244669748470187 loss_bn: 0.5148439407348633
task 1 iter 3800 loss: 13188.529296875 tv_loss: 0.23941323161125183 norm_loss: 0.8540996313095093 task_loss: 0.00038963466067798436 loss_bn: 0.45846277475357056
task 1 iter 3900 loss: 13015.091796875 tv_loss: 0.23821496963500977 norm_loss: 0.8540300726890564 task_loss: 0.00039074354572221637 loss_bn: 0.4411894977092743
task 1 iter 4000 loss: 13829.580078125 tv_loss: 0.23705092072486877 norm_loss: 0.8540576696395874 task_loss: 0.0003660988004412502 loss_bn: 0.522868812084198
task 1 iter 4100 loss: 13577.689453125 tv_loss: 0.2361888438463211 norm_loss: 0.8540478944778442 task_loss: 0.00035634468076750636 loss_bn: 0.49779585003852844
task 1 iter 4200 loss: 14125.552734375 tv_loss: 0.23504307866096497 norm_loss: 0.8539953231811523 task_loss: 0.0003713106270879507 loss_bn: 0.5524963140487671
task 1 iter 4300 loss: 13508.677734375 tv_loss: 0.23419132828712463 norm_loss: 0.8540053367614746 task_loss: 0.00036187440855428576 loss_bn: 0.4909018278121948
task 1 iter 4400 loss: 13885.064453125 tv_loss: 0.23336318135261536 norm_loss: 0.8539769053459167 task_loss: 0.00035750670940615237 loss_bn: 0.5286207795143127
task 1 iter 4500 loss: 14044.8916015625 tv_loss: 0.23275549709796906 norm_loss: 0.8540202379226685 task_loss: 0.0003306815924588591 loss_bn: 0.544834554195404
task 1 iter 4600 loss: 12789.150390625 tv_loss: 0.23199060559272766 norm_loss: 0.8539716005325317 task_loss: 0.00033825289574451745 loss_bn: 0.4192410111427307
task 1 iter 4700 loss: 13288.685546875 tv_loss: 0.23118659853935242 norm_loss: 0.8539384603500366 task_loss: 0.0003093944687861949 loss_bn: 0.4695242643356323
task 1 iter 4800 loss: 13212.6484375 tv_loss: 0.23065903782844543 norm_loss: 0.8539693355560303 task_loss: 0.00031688209855929017 loss_bn: 0.4618200957775116
task 1 iter 4900 loss: 13029.310546875 tv_loss: 0.2299143671989441 norm_loss: 0.8539304137229919 task_loss: 0.00031427183421328664 loss_bn: 0.4435587227344513
task 1 iter 5000 loss: 12805.759765625 tv_loss: 0.2294129878282547 norm_loss: 0.8539080619812012 task_loss: 0.000307169888401404 loss_bn: 0.42130205035209656
task 1 iter 5100 loss: 9512.40625 tv_loss: 0.2289317548274994 norm_loss: 0.8537906408309937 task_loss: 0.0003035945992451161 loss_bn: 0.09212466329336166
task 1 iter 5200 loss: 9469.6337890625 tv_loss: 0.2287234365940094 norm_loss: 0.8537707328796387 task_loss: 0.0002937231620308012 loss_bn: 0.08796815574169159
task 1 iter 5300 loss: 9433.3310546875 tv_loss: 0.22853973507881165 norm_loss: 0.8537678718566895 task_loss: 0.0002859231026377529 loss_bn: 0.0844205766916275
task 1 iter 5400 loss: 9509.427734375 tv_loss: 0.22837796807289124 norm_loss: 0.8537778854370117 task_loss: 0.00027864528237842023 loss_bn: 0.09209461510181427
task 1 iter 5500 loss: 9470.73046875 tv_loss: 0.22817999124526978 norm_loss: 0.8537908792495728 task_loss: 0.00027082173619419336 loss_bn: 0.08829203993082047
task 1 iter 5600 loss: 9465.70703125 tv_loss: 0.22802028059959412 norm_loss: 0.8538044095039368 task_loss: 0.0002646637731231749 loss_bn: 0.08783943206071854
task 1 iter 5700 loss: 9450.6318359375 tv_loss: 0.22786876559257507 norm_loss: 0.8538123369216919 task_loss: 0.00025957924663089216 loss_bn: 0.08637635409832001
task 1 iter 5800 loss: 9453.59765625 tv_loss: 0.2277170717716217 norm_loss: 0.8538181781768799 task_loss: 0.00025604592519812286 loss_bn: 0.08670395612716675
task 1 iter 5900 loss: 9445.6025390625 tv_loss: 0.2275751829147339 norm_loss: 0.8538243770599365 task_loss: 0.0002521828864701092 loss_bn: 0.08593830466270447
task 1 iter 6000 loss: 9428.1884765625 tv_loss: 0.22745317220687866 norm_loss: 0.8538323640823364 task_loss: 0.00024730974109843373 loss_bn: 0.08423889428377151
task 1 iter 6100 loss: 9438.4345703125 tv_loss: 0.22730067372322083 norm_loss: 0.8538366556167603 task_loss: 0.00024192998534999788 loss_bn: 0.08531459420919418
task 1 iter 6200 loss: 9474.9775390625 tv_loss: 0.22712603211402893 norm_loss: 0.85383141040802 task_loss: 0.0002388946304563433 loss_bn: 0.08900607377290726
task 1 iter 6300 loss: 9463.2177734375 tv_loss: 0.22698435187339783 norm_loss: 0.853834867477417 task_loss: 0.00023568241158500314 loss_bn: 0.08786021918058395
task 1 iter 6400 loss: 9460.9931640625 tv_loss: 0.22685039043426514 norm_loss: 0.8538362383842468 task_loss: 0.0002330223360331729 loss_bn: 0.08766431361436844
task 1 iter 6500 loss: 9456.220703125 tv_loss: 0.22670920193195343 norm_loss: 0.8538353443145752 task_loss: 0.00023007167328614742 loss_bn: 0.08721891045570374
task 1 iter 6600 loss: 9432.8876953125 tv_loss: 0.2265835404396057 norm_loss: 0.8538389205932617 task_loss: 0.00022671041369903833 loss_bn: 0.08491689711809158
task 1 iter 6700 loss: 9410.734375 tv_loss: 0.22645069658756256 norm_loss: 0.8538388013839722 task_loss: 0.0002249832614324987 loss_bn: 0.08272026479244232
task 1 iter 6800 loss: 9452.44140625 tv_loss: 0.22630387544631958 norm_loss: 0.8538325428962708 task_loss: 0.00022264523431658745 loss_bn: 0.08692216128110886
task 1 iter 6900 loss: 9446.044921875 tv_loss: 0.2261676788330078 norm_loss: 0.8538312315940857 task_loss: 0.000220065179746598 loss_bn: 0.08631093055009842
task 1 iter 7000 loss: 9432.8037109375 tv_loss: 0.22604304552078247 norm_loss: 0.8538293838500977 task_loss: 0.0002175930712837726 loss_bn: 0.08501467853784561
task 1 iter 7100 loss: 9432.23828125 tv_loss: 0.2259240746498108 norm_loss: 0.8538268804550171 task_loss: 0.0002151480148313567 loss_bn: 0.08498624712228775
task 1 iter 7200 loss: 9418.775390625 tv_loss: 0.22581028938293457 norm_loss: 0.8538249135017395 task_loss: 0.00021318432118277997 loss_bn: 0.08366266638040543
task 1 iter 7300 loss: 9398.921875 tv_loss: 0.22568652033805847 norm_loss: 0.8538169264793396 task_loss: 0.00021178019233047962 loss_bn: 0.08170062303543091
task 1 iter 7400 loss: 9370.662109375 tv_loss: 0.22556692361831665 norm_loss: 0.8538177013397217 task_loss: 0.00020985839364584535 loss_bn: 0.0788942202925682
task 1 iter 7500 loss: 9367.0048828125 tv_loss: 0.22544527053833008 norm_loss: 0.853812575340271 task_loss: 0.00020799244521185756 loss_bn: 0.07855351269245148
task 1 iter 7600 loss: 9377.1171875 tv_loss: 0.22531962394714355 norm_loss: 0.8538038730621338 task_loss: 0.00020666373893618584 loss_bn: 0.07958802580833435
task 1 iter 7700 loss: 9427.3212890625 tv_loss: 0.22520507872104645 norm_loss: 0.8538047075271606 task_loss: 0.00020406031399033964 loss_bn: 0.08463472127914429
task 1 iter 7800 loss: 9397.0166015625 tv_loss: 0.22509658336639404 norm_loss: 0.853803277015686 task_loss: 0.00020161052816547453 loss_bn: 0.08163127303123474
task 1 iter 7900 loss: 9368.8984375 tv_loss: 0.2249699980020523 norm_loss: 0.8537963628768921 task_loss: 0.0001997250219574198 loss_bn: 0.0788465291261673
task 1 iter 8000 loss: 9340.666015625 tv_loss: 0.22484908998012543 norm_loss: 0.8537926077842712 task_loss: 0.00019794564286712557 loss_bn: 0.07604605704545975
task 1 iter 8100 loss: 9373.5029296875 tv_loss: 0.22472551465034485 norm_loss: 0.853783130645752 task_loss: 0.00019696980598382652 loss_bn: 0.07935023307800293
task 1 iter 8200 loss: 9374.6240234375 tv_loss: 0.22459203004837036 norm_loss: 0.8537731170654297 task_loss: 0.00019598282233346254 loss_bn: 0.0794835090637207
task 1 iter 8300 loss: 9364.728515625 tv_loss: 0.22447648644447327 norm_loss: 0.8537687659263611 task_loss: 0.00019466341473162174 loss_bn: 0.07851274311542511
task 1 iter 8400 loss: 9351.3212890625 tv_loss: 0.22437018156051636 norm_loss: 0.8537630438804626 task_loss: 0.00019346599583514035 loss_bn: 0.07719068229198456
task 1 iter 8500 loss: 9337.6552734375 tv_loss: 0.2242661714553833 norm_loss: 0.8537577390670776 task_loss: 0.00019245011208113283 loss_bn: 0.07584064453840256
task 1 iter 8600 loss: 9344.1728515625 tv_loss: 0.22416658699512482 norm_loss: 0.853753387928009 task_loss: 0.00019141002849210054 loss_bn: 0.07650814950466156
task 1 iter 8700 loss: 9329.8095703125 tv_loss: 0.2240729182958603 norm_loss: 0.8537495732307434 task_loss: 0.00019039513426832855 loss_bn: 0.07508660852909088
task 1 iter 8800 loss: 9348.9794921875 tv_loss: 0.2239619493484497 norm_loss: 0.8537373542785645 task_loss: 0.00018889503553509712 loss_bn: 0.07703191041946411
task 1 iter 8900 loss: 9316.517578125 tv_loss: 0.2238604724407196 norm_loss: 0.8537329435348511 task_loss: 0.0001873931469162926 loss_bn: 0.07380636036396027
task 1 iter 9000 loss: 9299.1328125 tv_loss: 0.223751962184906 norm_loss: 0.8537249565124512 task_loss: 0.00018691920558921993 loss_bn: 0.07208158075809479
task 1 iter 9100 loss: 9395.1923828125 tv_loss: 0.2236599326133728 norm_loss: 0.8537204265594482 task_loss: 0.0001842514902818948 loss_bn: 0.0817197635769844
task 1 iter 9200 loss: 9373.607421875 tv_loss: 0.22354836761951447 norm_loss: 0.8537122011184692 task_loss: 0.00018286689009983093 loss_bn: 0.07958434522151947
task 1 iter 9300 loss: 9362.517578125 tv_loss: 0.2234431803226471 norm_loss: 0.8537054061889648 task_loss: 0.00018163961067330092 loss_bn: 0.07849560678005219
task 1 iter 9400 loss: 9353.296875 tv_loss: 0.22334438562393188 norm_loss: 0.853698194026947 task_loss: 0.00018049524805974215 loss_bn: 0.0775931105017662
task 1 iter 9500 loss: 9370.3056640625 tv_loss: 0.22324544191360474 norm_loss: 0.8536878824234009 task_loss: 0.00017944865976460278 loss_bn: 0.07931575924158096
task 1 iter 9600 loss: 9336.791015625 tv_loss: 0.22315260767936707 norm_loss: 0.8536809682846069 task_loss: 0.00017872423632070422 loss_bn: 0.07597937434911728
task 1 iter 9700 loss: 9321.658203125 tv_loss: 0.2230530083179474 norm_loss: 0.853672981262207 task_loss: 0.00017779403424356133 loss_bn: 0.07448441535234451
task 1 iter 9800 loss: 9311.3740234375 tv_loss: 0.2229551374912262 norm_loss: 0.8536655306816101 task_loss: 0.0001772185933077708 loss_bn: 0.07347012311220169
task 1 iter 9900 loss: 9329.1171875 tv_loss: 0.22285647690296173 norm_loss: 0.8536537885665894 task_loss: 0.00017629022477194667 loss_bn: 0.07526642084121704
task 1 iter 10000 loss: 9320.1943359375 tv_loss: 0.22275784611701965 norm_loss: 0.8536452651023865 task_loss: 0.00017534231301397085 loss_bn: 0.07439316809177399
task 2 iter 100 loss: 134261.546875 tv_loss: 0.4997050166130066 norm_loss: 0.9471299648284912 task_loss: 0.0041186148300766945 loss_bn: 12.432841300964355
task 2 iter 200 loss: 68069.796875 tv_loss: 0.43664801120758057 norm_loss: 0.9166884422302246 task_loss: 0.0022958924528211355 loss_bn: 5.8629655838012695
task 2 iter 300 loss: 47903.68359375 tv_loss: 0.4054885506629944 norm_loss: 0.8925099968910217 task_loss: 0.001692898920737207 loss_bn: 3.8768746852874756
task 2 iter 400 loss: 37606.4140625 tv_loss: 0.38509559631347656 norm_loss: 0.87787926197052 task_loss: 0.0013908084947615862 loss_bn: 2.8650031089782715
task 2 iter 500 loss: 31659.23828125 tv_loss: 0.3700968027114868 norm_loss: 0.8701711893081665 task_loss: 0.0011568255722522736 loss_bn: 2.2804834842681885
task 2 iter 600 loss: 28211.416015625 tv_loss: 0.3583078682422638 norm_loss: 0.8660668134689331 task_loss: 0.0009919812437146902 loss_bn: 1.941571831703186
task 2 iter 700 loss: 25592.416015625 tv_loss: 0.3485378623008728 norm_loss: 0.8636670112609863 task_loss: 0.0008735479204915464 loss_bn: 1.6833537817001343
task 2 iter 800 loss: 23668.455078125 tv_loss: 0.3400046229362488 norm_loss: 0.86210036277771 task_loss: 0.0007882245699875057 loss_bn: 1.4934628009796143
task 2 iter 900 loss: 22181.3125 tv_loss: 0.3324442207813263 norm_loss: 0.8610068559646606 task_loss: 0.000708440609741956 loss_bn: 1.3467155694961548
task 2 iter 1000 loss: 20410.30859375 tv_loss: 0.32543864846229553 norm_loss: 0.8601893186569214 task_loss: 0.0006636292673647404 loss_bn: 1.1709506511688232
task 2 iter 1100 loss: 19568.0 tv_loss: 0.31895750761032104 norm_loss: 0.8595440983772278 task_loss: 0.0006142859347164631 loss_bn: 1.087923526763916
task 2 iter 1200 loss: 18491.26171875 tv_loss: 0.31299471855163574 norm_loss: 0.859012246131897 task_loss: 0.0005920996773056686 loss_bn: 0.9810630679130554
task 2 iter 1300 loss: 17689.08984375 tv_loss: 0.30740225315093994 norm_loss: 0.8585192561149597 task_loss: 0.0005634739063680172 loss_bn: 0.9016809463500977
task 2 iter 1400 loss: 19342.2109375 tv_loss: 0.30156537890434265 norm_loss: 0.8579920530319214 task_loss: 0.0005108836339786649 loss_bn: 1.0681045055389404
task 2 iter 1500 loss: 18203.76171875 tv_loss: 0.2966799736022949 norm_loss: 0.8575847744941711 task_loss: 0.0005144598544575274 loss_bn: 0.9546800255775452
task 2 iter 1600 loss: 17612.30859375 tv_loss: 0.2927588224411011 norm_loss: 0.8573721647262573 task_loss: 0.0004920744686387479 loss_bn: 0.8960103988647461
task 2 iter 1700 loss: 17634.3828125 tv_loss: 0.28867486119270325 norm_loss: 0.8570567965507507 task_loss: 0.0004725215840153396 loss_bn: 0.8987693190574646
task 2 iter 1800 loss: 16729.337890625 tv_loss: 0.28495168685913086 norm_loss: 0.856797456741333 task_loss: 0.00046350760385394096 loss_bn: 0.8086518049240112
task 2 iter 1900 loss: 16597.7734375 tv_loss: 0.2816438674926758 norm_loss: 0.8566128015518188 task_loss: 0.00044699563295580447 loss_bn: 0.7958782315254211
task 2 iter 2000 loss: 16083.228515625 tv_loss: 0.27838751673698425 norm_loss: 0.8563656806945801 task_loss: 0.00043508477392606437 loss_bn: 0.7448223829269409
task 2 iter 2100 loss: 16164.3701171875 tv_loss: 0.2754136919975281 norm_loss: 0.8562158346176147 task_loss: 0.0004111322923563421 loss_bn: 0.7533557415008545
task 2 iter 2200 loss: 16570.16015625 tv_loss: 0.2721056640148163 norm_loss: 0.855965256690979 task_loss: 0.00040522313793189824 loss_bn: 0.794277548789978
task 2 iter 2300 loss: 16218.908203125 tv_loss: 0.26939988136291504 norm_loss: 0.8558156490325928 task_loss: 0.00037928036181256175 loss_bn: 0.7595884203910828
task 2 iter 2400 loss: 15525.6337890625 tv_loss: 0.26647818088531494 norm_loss: 0.8555991649627686 task_loss: 0.00036046188324689865 loss_bn: 0.6906948089599609
task 2 iter 2500 loss: 14694.845703125 tv_loss: 0.263897567987442 norm_loss: 0.8554949760437012 task_loss: 0.000351703871274367 loss_bn: 0.6078335642814636
task 2 iter 2600 loss: 15547.9892578125 tv_loss: 0.2612043619155884 norm_loss: 0.8552804589271545 task_loss: 0.00034739021793939173 loss_bn: 0.6934325098991394
task 2 iter 2700 loss: 15064.169921875 tv_loss: 0.25869041681289673 norm_loss: 0.8550853729248047 task_loss: 0.0003483388863969594 loss_bn: 0.645261287689209
task 2 iter 2800 loss: 14316.47265625 tv_loss: 0.25649797916412354 norm_loss: 0.8549860119819641 task_loss: 0.0003246019477955997 loss_bn: 0.5708502531051636
task 2 iter 2900 loss: 14456.427734375 tv_loss: 0.2543524205684662 norm_loss: 0.8548082113265991 task_loss: 0.00033445036388002336 loss_bn: 0.5849466323852539
task 2 iter 3000 loss: 14163.1943359375 tv_loss: 0.2524855434894562 norm_loss: 0.8547084927558899 task_loss: 0.00031395762925967574 loss_bn: 0.5559464693069458
task 2 iter 3100 loss: 14516.537109375 tv_loss: 0.25024235248565674 norm_loss: 0.8545347452163696 task_loss: 0.0003227786219213158 loss_bn: 0.5913888216018677
task 2 iter 3200 loss: 13468.169921875 tv_loss: 0.24839739501476288 norm_loss: 0.8544262647628784 task_loss: 0.00029571523191407323 loss_bn: 0.4869496822357178
task 2 iter 3300 loss: 14250.615234375 tv_loss: 0.24707721173763275 norm_loss: 0.8543930649757385 task_loss: 0.0003008209459949285 loss_bn: 0.5651894211769104
task 2 iter 3400 loss: 14238.34765625 tv_loss: 0.24546344578266144 norm_loss: 0.8543143272399902 task_loss: 0.00029834540328010917 loss_bn: 0.5640822649002075
task 2 iter 3500 loss: 14417.4609375 tv_loss: 0.2438325434923172 norm_loss: 0.8541833758354187 task_loss: 0.00030297652119770646 loss_bn: 0.582094669342041
task 2 iter 3600 loss: 14114.603515625 tv_loss: 0.2423238456249237 norm_loss: 0.8541311621665955 task_loss: 0.0002884936984628439 loss_bn: 0.5520209670066833
task 2 iter 3700 loss: 13470.01171875 tv_loss: 0.24111181497573853 norm_loss: 0.8541007041931152 task_loss: 0.0002785955439321697 loss_bn: 0.48770344257354736
task 2 iter 3800 loss: 13758.0263671875 tv_loss: 0.23996606469154358 norm_loss: 0.8541249632835388 task_loss: 0.0002640861494001001 loss_bn: 0.5166370868682861
task 2 iter 3900 loss: 13250.1494140625 tv_loss: 0.23892873525619507 norm_loss: 0.8541405200958252 task_loss: 0.00025429041124880314 loss_bn: 0.4659421741962433
task 2 iter 4000 loss: 13111.947265625 tv_loss: 0.23777639865875244 norm_loss: 0.8540726900100708 task_loss: 0.00025404177722521126 loss_bn: 0.4522038698196411
task 2 iter 4100 loss: 14159.3525390625 tv_loss: 0.23650337755680084 norm_loss: 0.8540371060371399 task_loss: 0.0002586440823506564 loss_bn: 0.5569466948509216
task 2 iter 4200 loss: 12693.3701171875 tv_loss: 0.2354893535375595 norm_loss: 0.854004979133606 task_loss: 0.0002348471462028101 loss_bn: 0.41062870621681213
task 2 iter 4300 loss: 13412.115234375 tv_loss: 0.23491396009922028 norm_loss: 0.8540757894515991 task_loss: 0.0002370434522163123 loss_bn: 0.4824162721633911
task 2 iter 4400 loss: 13732.1669921875 tv_loss: 0.2338103950023651 norm_loss: 0.8539954423904419 task_loss: 0.00024181496701203287 loss_bn: 0.5144650340080261
task 2 iter 4500 loss: 12976.025390625 tv_loss: 0.23290812969207764 norm_loss: 0.8540135622024536 task_loss: 0.00022372257080860436 loss_bn: 0.4390227198600769
task 2 iter 4600 loss: 12736.96875 tv_loss: 0.2324972301721573 norm_loss: 0.8540712594985962 task_loss: 0.00022097016335465014 loss_bn: 0.41509097814559937
task 2 iter 4700 loss: 12463.98046875 tv_loss: 0.23155927658081055 norm_loss: 0.8540024161338806 task_loss: 0.00021079603175166994 loss_bn: 0.3879721164703369
task 2 iter 4800 loss: 12563.35546875 tv_loss: 0.23100757598876953 norm_loss: 0.8540151119232178 task_loss: 0.0002147737395716831 loss_bn: 0.39786261320114136
task 2 iter 4900 loss: 12569.3388671875 tv_loss: 0.23025107383728027 norm_loss: 0.8539683818817139 task_loss: 0.00020850000146310776 loss_bn: 0.39857804775238037
task 2 iter 5000 loss: 12821.259765625 tv_loss: 0.22980476915836334 norm_loss: 0.85396409034729 task_loss: 0.0002077301178360358 loss_bn: 0.4237864911556244
task 2 iter 5100 loss: 9486.2109375 tv_loss: 0.22933343052864075 norm_loss: 0.8538497686386108 task_loss: 0.00020085583673790097 loss_bn: 0.09046946465969086
task 2 iter 5200 loss: 9451.400390625 tv_loss: 0.22911903262138367 norm_loss: 0.8538358211517334 task_loss: 0.00019445446378085762 loss_bn: 0.08706842362880707
task 2 iter 5300 loss: 9447.7333984375 tv_loss: 0.22892960906028748 norm_loss: 0.8538339734077454 task_loss: 0.00018902510055340827 loss_bn: 0.08675980567932129
task 2 iter 5400 loss: 9430.919921875 tv_loss: 0.22875824570655823 norm_loss: 0.8538413047790527 task_loss: 0.00018336290668230504 loss_bn: 0.08512946218252182
task 2 iter 5500 loss: 9428.3447265625 tv_loss: 0.2286018282175064 norm_loss: 0.8538519740104675 task_loss: 0.00017892700270749629 loss_bn: 0.08490719646215439
task 2 iter 5600 loss: 9399.458984375 tv_loss: 0.22844593226909637 norm_loss: 0.8538641333580017 task_loss: 0.0001747471105773002 loss_bn: 0.08204983919858932
task 2 iter 5700 loss: 9485.197265625 tv_loss: 0.22827064990997314 norm_loss: 0.8538733720779419 task_loss: 0.00016998243518173695 loss_bn: 0.0906638577580452
task 2 iter 5800 loss: 9451.1904296875 tv_loss: 0.22810566425323486 norm_loss: 0.8538858890533447 task_loss: 0.00016535648319404572 loss_bn: 0.08729840815067291
task 2 iter 5900 loss: 9440.5556640625 tv_loss: 0.22794100642204285 norm_loss: 0.8538922071456909 task_loss: 0.0001612408086657524 loss_bn: 0.08627156913280487
task 2 iter 6000 loss: 9441.2822265625 tv_loss: 0.2277684360742569 norm_loss: 0.85389244556427 task_loss: 0.0001578299852553755 loss_bn: 0.08637974411249161
task 2 iter 6100 loss: 9427.0322265625 tv_loss: 0.22761034965515137 norm_loss: 0.8538990616798401 task_loss: 0.0001543949038023129 loss_bn: 0.0849841758608818
task 2 iter 6200 loss: 9412.5166015625 tv_loss: 0.22746145725250244 norm_loss: 0.8539037704467773 task_loss: 0.00015203160000965 loss_bn: 0.08355291932821274
task 2 iter 6300 loss: 9397.8359375 tv_loss: 0.2273206114768982 norm_loss: 0.8539072871208191 task_loss: 0.00015029031783342361 loss_bn: 0.08210021257400513
task 2 iter 6400 loss: 9393.0009765625 tv_loss: 0.22718600928783417 norm_loss: 0.8539087176322937 task_loss: 0.00014862629177514464 loss_bn: 0.08163332939147949
task 2 iter 6500 loss: 9389.7060546875 tv_loss: 0.22704260051250458 norm_loss: 0.8539103269577026 task_loss: 0.00014712900156155229 loss_bn: 0.08131851255893707
task 2 iter 6600 loss: 9394.8935546875 tv_loss: 0.22690750658512115 norm_loss: 0.853909969329834 task_loss: 0.00014522753190249205 loss_bn: 0.08185800909996033
task 2 iter 6700 loss: 9381.830078125 tv_loss: 0.22677600383758545 norm_loss: 0.8539102077484131 task_loss: 0.00014355419261846691 loss_bn: 0.08056940138339996
task 2 iter 6800 loss: 9372.3740234375 tv_loss: 0.2266518473625183 norm_loss: 0.8539093732833862 task_loss: 0.00014224776532500982 loss_bn: 0.07963905483484268
task 2 iter 6900 loss: 9377.197265625 tv_loss: 0.22652599215507507 norm_loss: 0.8539084792137146 task_loss: 0.0001405492948833853 loss_bn: 0.0801403820514679
task 2 iter 7000 loss: 9356.1748046875 tv_loss: 0.22640012204647064 norm_loss: 0.85390704870224 task_loss: 0.00013927074905950576 loss_bn: 0.07805371284484863
task 2 iter 7100 loss: 9378.66796875 tv_loss: 0.22626268863677979 norm_loss: 0.8539012670516968 task_loss: 0.00013784231850877404 loss_bn: 0.08032455295324326
task 2 iter 7200 loss: 9372.791015625 tv_loss: 0.2261287271976471 norm_loss: 0.8538988828659058 task_loss: 0.0001361224421998486 loss_bn: 0.07975757867097855
task 2 iter 7300 loss: 9390.1015625 tv_loss: 0.22599256038665771 norm_loss: 0.8538975119590759 task_loss: 0.00013350206427276134 loss_bn: 0.08151770383119583
task 2 iter 7400 loss: 9338.9501953125 tv_loss: 0.22584854066371918 norm_loss: 0.8538950681686401 task_loss: 0.0001312122622039169 loss_bn: 0.07642936706542969
task 2 iter 7500 loss: 9312.7705078125 tv_loss: 0.22571472823619843 norm_loss: 0.853891134262085 task_loss: 0.00012926421186421067 loss_bn: 0.07383617758750916
task 2 iter 7600 loss: 9473.4541015625 tv_loss: 0.22559650242328644 norm_loss: 0.8538876175880432 task_loss: 0.00012774637434631586 loss_bn: 0.08992443978786469
task 2 iter 7700 loss: 9454.3271484375 tv_loss: 0.22546188533306122 norm_loss: 0.8538831472396851 task_loss: 0.00012620804773177952 loss_bn: 0.08803291618824005
task 2 iter 7800 loss: 9439.7998046875 tv_loss: 0.22533756494522095 norm_loss: 0.8538777828216553 task_loss: 0.00012487733329180628 loss_bn: 0.08660011738538742
task 2 iter 7900 loss: 9423.23828125 tv_loss: 0.22521577775478363 norm_loss: 0.8538726568222046 task_loss: 0.00012392194184940308 loss_bn: 0.0849597230553627
task 2 iter 8000 loss: 9426.51953125 tv_loss: 0.22510221600532532 norm_loss: 0.8538674116134644 task_loss: 0.00012282685202080756 loss_bn: 0.08530530333518982
task 2 iter 8100 loss: 9418.6005859375 tv_loss: 0.22498448193073273 norm_loss: 0.8538621068000793 task_loss: 0.00012198132026242092 loss_bn: 0.08452834188938141
task 2 iter 8200 loss: 9397.4892578125 tv_loss: 0.22486266493797302 norm_loss: 0.8538573980331421 task_loss: 0.00012122519547119737 loss_bn: 0.08243070542812347
task 2 iter 8300 loss: 9408.1630859375 tv_loss: 0.2247564196586609 norm_loss: 0.853850245475769 task_loss: 0.00012019807763863355 loss_bn: 0.08351653814315796
task 2 iter 8400 loss: 9395.4111328125 tv_loss: 0.2246374487876892 norm_loss: 0.8538424968719482 task_loss: 0.00011930131586268544 loss_bn: 0.08225924521684647
task 2 iter 8500 loss: 9391.57421875 tv_loss: 0.22452691197395325 norm_loss: 0.8538360595703125 task_loss: 0.00011839247599709779 loss_bn: 0.0818922221660614
task 2 iter 8600 loss: 9388.1806640625 tv_loss: 0.2244199812412262 norm_loss: 0.8538298606872559 task_loss: 0.00011778252519434318 loss_bn: 0.08156609535217285
task 2 iter 8700 loss: 9376.515625 tv_loss: 0.2243131399154663 norm_loss: 0.8538234233856201 task_loss: 0.00011704501957865432 loss_bn: 0.08041457086801529
task 2 iter 8800 loss: 9390.9775390625 tv_loss: 0.2241952121257782 norm_loss: 0.853814423084259 task_loss: 0.00011653098044916987 loss_bn: 0.08187608420848846
task 2 iter 8900 loss: 9380.3173828125 tv_loss: 0.2240825742483139 norm_loss: 0.8538062572479248 task_loss: 0.00011574038217077032 loss_bn: 0.0808272510766983
task 2 iter 9000 loss: 9424.40625 tv_loss: 0.22398844361305237 norm_loss: 0.8538000583648682 task_loss: 0.00011478125816211104 loss_bn: 0.08525283634662628
task 2 iter 9100 loss: 9388.1845703125 tv_loss: 0.2238810658454895 norm_loss: 0.853793203830719 task_loss: 0.00011413778702262789 loss_bn: 0.08164507150650024
task 2 iter 9200 loss: 9382.681640625 tv_loss: 0.22377565503120422 norm_loss: 0.8537869453430176 task_loss: 0.00011351480497978628 loss_bn: 0.08110834658145905
task 2 iter 9300 loss: 9349.68359375 tv_loss: 0.22366943955421448 norm_loss: 0.8537797927856445 task_loss: 0.00011293651914456859 loss_bn: 0.07782252877950668
task 2 iter 9400 loss: 9367.537109375 tv_loss: 0.22357335686683655 norm_loss: 0.8537724018096924 task_loss: 0.00011234054545639083 loss_bn: 0.07962211966514587
task 2 iter 9500 loss: 9371.9775390625 tv_loss: 0.22346961498260498 norm_loss: 0.8537637591362 task_loss: 0.0001117827559937723 loss_bn: 0.08008147776126862
task 2 iter 9600 loss: 9357.1083984375 tv_loss: 0.22336773574352264 norm_loss: 0.8537555932998657 task_loss: 0.00011121845454908907 loss_bn: 0.07860936224460602
task 2 iter 9700 loss: 9359.998046875 tv_loss: 0.2232692539691925 norm_loss: 0.853750467300415 task_loss: 0.00011118772090412676 loss_bn: 0.07890474051237106
task 2 iter 9800 loss: 9391.208984375 tv_loss: 0.22316601872444153 norm_loss: 0.8537420630455017 task_loss: 0.00011040829122066498 loss_bn: 0.08204305917024612
task 2 iter 9900 loss: 9353.5859375 tv_loss: 0.2230648547410965 norm_loss: 0.8537352085113525 task_loss: 0.0001094947729143314 loss_bn: 0.07829773426055908
task 2 iter 10000 loss: 9333.14453125 tv_loss: 0.22296354174613953 norm_loss: 0.8537272214889526 task_loss: 0.00010874606959987432 loss_bn: 0.07627012580633163
task 3 iter 100 loss: 154678.421875 tv_loss: 0.513007640838623 norm_loss: 0.9504923224449158 task_loss: 0.0038754097186028957 loss_bn: 14.473465919494629
task 3 iter 200 loss: 77730.96875 tv_loss: 0.448506623506546 norm_loss: 0.9242225885391235 task_loss: 0.0020798419136554003 loss_bn: 6.823590278625488
task 3 iter 300 loss: 55755.90625 tv_loss: 0.41589874029159546 norm_loss: 0.9013155102729797 task_loss: 0.001555939787067473 loss_bn: 4.654556751251221
task 3 iter 400 loss: 44366.14453125 tv_loss: 0.3942945599555969 norm_loss: 0.8848128318786621 task_loss: 0.001319116447120905 loss_bn: 3.534667491912842
task 3 iter 500 loss: 37114.16796875 tv_loss: 0.37842661142349243 norm_loss: 0.874867856502533 task_loss: 0.0011269057868048549 loss_bn: 2.821495771408081
task 3 iter 600 loss: 32754.775390625 tv_loss: 0.3658986985683441 norm_loss: 0.8691238760948181 task_loss: 0.0009695467888377607 loss_bn: 2.3929991722106934
task 3 iter 700 loss: 29881.7109375 tv_loss: 0.3557860255241394 norm_loss: 0.865732729434967 task_loss: 0.00085371796740219 loss_bn: 2.1103434562683105
task 3 iter 800 loss: 27800.30859375 tv_loss: 0.3463561236858368 norm_loss: 0.86336350440979 task_loss: 0.0007369756931439042 loss_bn: 1.9058339595794678
task 3 iter 900 loss: 24900.814453125 tv_loss: 0.33828145265579224 norm_loss: 0.8618807792663574 task_loss: 0.0006758946692571044 loss_bn: 1.6180589199066162
task 3 iter 1000 loss: 23656.66015625 tv_loss: 0.3313707411289215 norm_loss: 0.8609248399734497 task_loss: 0.0006336400983855128 loss_bn: 1.495091199874878
task 3 iter 1100 loss: 22234.7734375 tv_loss: 0.3250131607055664 norm_loss: 0.8602359294891357 task_loss: 0.0005968909244984388 loss_bn: 1.3540223836898804
task 3 iter 1200 loss: 21425.390625 tv_loss: 0.31814292073249817 norm_loss: 0.85948246717453 task_loss: 0.0005625176709145308 loss_bn: 1.2742499113082886
task 3 iter 1300 loss: 20712.67578125 tv_loss: 0.3121945261955261 norm_loss: 0.8589502573013306 task_loss: 0.0005105992313474417 loss_bn: 1.2040894031524658
task 3 iter 1400 loss: 19741.001953125 tv_loss: 0.3067752718925476 norm_loss: 0.8585243225097656 task_loss: 0.0004804879135917872 loss_bn: 1.1077032089233398
task 3 iter 1500 loss: 18525.87890625 tv_loss: 0.30177438259124756 norm_loss: 0.8581305742263794 task_loss: 0.0004616724618244916 loss_bn: 0.986822783946991
task 3 iter 1600 loss: 17832.66015625 tv_loss: 0.2961796522140503 norm_loss: 0.8576363921165466 task_loss: 0.0004350040981080383 loss_bn: 0.9183176755905151
task 3 iter 1700 loss: 18655.076171875 tv_loss: 0.29100164771080017 norm_loss: 0.8572793006896973 task_loss: 0.00041801983024924994 loss_bn: 1.0011380910873413
task 3 iter 1800 loss: 17126.080078125 tv_loss: 0.2864989638328552 norm_loss: 0.8569712042808533 task_loss: 0.00037443931796588004 loss_bn: 0.8490273952484131
task 3 iter 1900 loss: 17754.95703125 tv_loss: 0.2828772962093353 norm_loss: 0.8567712306976318 task_loss: 0.0003623367811087519 loss_bn: 0.9122723937034607
task 3 iter 2000 loss: 16401.37890625 tv_loss: 0.27918070554733276 norm_loss: 0.856560230255127 task_loss: 0.00035068951547145844 loss_bn: 0.7772788405418396
task 3 iter 2100 loss: 15978.896484375 tv_loss: 0.2758767008781433 norm_loss: 0.8563938140869141 task_loss: 0.00034861560561694205 loss_bn: 0.7352508306503296
task 3 iter 2200 loss: 15656.736328125 tv_loss: 0.27266502380371094 norm_loss: 0.8562260270118713 task_loss: 0.0003295025380793959 loss_bn: 0.7034258842468262
task 3 iter 2300 loss: 15623.3974609375 tv_loss: 0.2694666385650635 norm_loss: 0.8559826612472534 task_loss: 0.00032856050529517233 loss_bn: 0.7003768682479858
task 3 iter 2400 loss: 14958.859375 tv_loss: 0.2664114236831665 norm_loss: 0.855786919593811 task_loss: 0.0003045880876015872 loss_bn: 0.6343890428543091
task 3 iter 2500 loss: 15070.4765625 tv_loss: 0.2638019919395447 norm_loss: 0.8556731939315796 task_loss: 0.00029794653528369963 loss_bn: 0.6457569599151611
task 3 iter 2600 loss: 15031.9306640625 tv_loss: 0.26104480028152466 norm_loss: 0.8554614186286926 task_loss: 0.00029398855986073613 loss_bn: 0.6421813368797302
task 3 iter 2700 loss: 14597.0546875 tv_loss: 0.25853633880615234 norm_loss: 0.855294942855835 task_loss: 0.00028807204216718674 loss_bn: 0.5989444255828857
task 3 iter 2800 loss: 14414.14453125 tv_loss: 0.25604283809661865 norm_loss: 0.8551047444343567 task_loss: 0.00027646723901852965 loss_bn: 0.5809845328330994
task 3 iter 2900 loss: 14201.6484375 tv_loss: 0.2537362575531006 norm_loss: 0.8550359010696411 task_loss: 0.00027164461789652705 loss_bn: 0.5598750710487366
task 3 iter 3000 loss: 13551.8515625 tv_loss: 0.25151482224464417 norm_loss: 0.8549149632453918 task_loss: 0.0002728442777879536 loss_bn: 0.4950266480445862
task 3 iter 3100 loss: 14094.529296875 tv_loss: 0.24966903030872345 norm_loss: 0.8548165559768677 task_loss: 0.000257217267062515 loss_bn: 0.5495675206184387
task 3 iter 3200 loss: 13828.0693359375 tv_loss: 0.24788905680179596 norm_loss: 0.8546950221061707 task_loss: 0.0002479444956406951 loss_bn: 0.5231536030769348
task 3 iter 3300 loss: 14016.7119140625 tv_loss: 0.24625271558761597 norm_loss: 0.8546203374862671 task_loss: 0.0002465124416630715 loss_bn: 0.5421232581138611
task 3 iter 3400 loss: 14291.814453125 tv_loss: 0.24450698494911194 norm_loss: 0.8545334339141846 task_loss: 0.0002525409508962184 loss_bn: 0.5696775913238525
task 3 iter 3500 loss: 14940.380859375 tv_loss: 0.24281738698482513 norm_loss: 0.8544740080833435 task_loss: 0.00023695560230407864 loss_bn: 0.6347662806510925
task 3 iter 3600 loss: 13683.427734375 tv_loss: 0.24158483743667603 norm_loss: 0.854400634765625 task_loss: 0.00023474956105928868 loss_bn: 0.509178876876831
task 3 iter 3700 loss: 13909.046875 tv_loss: 0.24011027812957764 norm_loss: 0.8543505668640137 task_loss: 0.00022530026035383344 loss_bn: 0.5319000482559204
task 3 iter 3800 loss: 13076.544921875 tv_loss: 0.23883292078971863 norm_loss: 0.8543233275413513 task_loss: 0.00022438479936681688 loss_bn: 0.448699027299881
task 3 iter 3900 loss: 13762.1064453125 tv_loss: 0.23797348141670227 norm_loss: 0.8543296456336975 task_loss: 0.00021431126515381038 loss_bn: 0.517358124256134
task 3 iter 4000 loss: 13390.078125 tv_loss: 0.23686669766902924 norm_loss: 0.8543406128883362 task_loss: 0.00020977971144020557 loss_bn: 0.4802006185054779
task 3 iter 4100 loss: 13492.294921875 tv_loss: 0.23589441180229187 norm_loss: 0.8543338775634766 task_loss: 0.00019823326147161424 loss_bn: 0.49055424332618713
task 3 iter 4200 loss: 12695.076171875 tv_loss: 0.23499521613121033 norm_loss: 0.8543066382408142 task_loss: 0.00020156543178018183 loss_bn: 0.4108353555202484
task 3 iter 4300 loss: 13795.251953125 tv_loss: 0.23371368646621704 norm_loss: 0.8542203903198242 task_loss: 0.00020173608209006488 loss_bn: 0.5209502577781677
task 3 iter 4400 loss: 13542.728515625 tv_loss: 0.23308949172496796 norm_loss: 0.854228138923645 task_loss: 0.0001919350033858791 loss_bn: 0.4957944452762604
task 3 iter 4500 loss: 13106.015625 tv_loss: 0.23219439387321472 norm_loss: 0.8542053699493408 task_loss: 0.00019533165323082358 loss_bn: 0.4521208703517914
task 3 iter 4600 loss: 12978.7763671875 tv_loss: 0.23147886991500854 norm_loss: 0.8541723489761353 task_loss: 0.00019194994820281863 loss_bn: 0.4394710063934326
task 3 iter 4700 loss: 12980.9052734375 tv_loss: 0.23080143332481384 norm_loss: 0.8542037010192871 task_loss: 0.00018378961249254644 loss_bn: 0.439740926027298
task 3 iter 4800 loss: 12720.75390625 tv_loss: 0.22996379435062408 norm_loss: 0.8541440963745117 task_loss: 0.00017835172184277326 loss_bn: 0.4138481020927429
task 3 iter 4900 loss: 12582.0302734375 tv_loss: 0.22970518469810486 norm_loss: 0.8541638851165771 task_loss: 0.0001770705566741526 loss_bn: 0.3999713957309723
task 3 iter 5000 loss: 12271.85546875 tv_loss: 0.22886691987514496 norm_loss: 0.8541144132614136 task_loss: 0.00016953112208284438 loss_bn: 0.3690871596336365
task 3 iter 5100 loss: 9571.078125 tv_loss: 0.2284417748451233 norm_loss: 0.8540397882461548 task_loss: 0.00016490148846060038 loss_bn: 0.09913469851016998
task 3 iter 5200 loss: 9531.5283203125 tv_loss: 0.22823840379714966 norm_loss: 0.8540259599685669 task_loss: 0.00015974945563357323 loss_bn: 0.09524701535701752
task 3 iter 5300 loss: 9503.275390625 tv_loss: 0.22806358337402344 norm_loss: 0.8540261387825012 task_loss: 0.00015529763186350465 loss_bn: 0.0924677848815918
task 3 iter 5400 loss: 9531.8095703125 tv_loss: 0.2278868407011032 norm_loss: 0.8540293574333191 task_loss: 0.0001517964556114748 loss_bn: 0.09535464644432068
task 3 iter 5500 loss: 9511.544921875 tv_loss: 0.2277022898197174 norm_loss: 0.854038417339325 task_loss: 0.00014811560686212033 loss_bn: 0.0933578759431839
task 3 iter 5600 loss: 9498.1875 tv_loss: 0.22754719853401184 norm_loss: 0.854047417640686 task_loss: 0.00014483880659099668 loss_bn: 0.09204745292663574
task 3 iter 5700 loss: 9480.095703125 tv_loss: 0.22739997506141663 norm_loss: 0.8540549874305725 task_loss: 0.0001423749781679362 loss_bn: 0.09025686979293823
task 3 iter 5800 loss: 9468.9052734375 tv_loss: 0.2272576093673706 norm_loss: 0.8540613651275635 task_loss: 0.000140143878525123 loss_bn: 0.08915514498949051
task 3 iter 5900 loss: 9459.375 tv_loss: 0.22711756825447083 norm_loss: 0.8540656566619873 task_loss: 0.00013807199138682336 loss_bn: 0.08822004497051239
task 3 iter 6000 loss: 9475.755859375 tv_loss: 0.2269771844148636 norm_loss: 0.8540685176849365 task_loss: 0.00013554665201809257 loss_bn: 0.08988186717033386
task 3 iter 6100 loss: 9464.41015625 tv_loss: 0.22683237493038177 norm_loss: 0.8540711998939514 task_loss: 0.000133548368467018 loss_bn: 0.08876597136259079
task 3 iter 6200 loss: 9451.291015625 tv_loss: 0.22669748961925507 norm_loss: 0.8540730476379395 task_loss: 0.00013178469089325517 loss_bn: 0.087471142411232
task 3 iter 6300 loss: 9448.4453125 tv_loss: 0.22656461596488953 norm_loss: 0.8540748357772827 task_loss: 0.00013018024037592113 loss_bn: 0.087202288210392
task 3 iter 6400 loss: 9454.2578125 tv_loss: 0.22644557058811188 norm_loss: 0.854076623916626 task_loss: 0.00012826385500375181 loss_bn: 0.08780202269554138
task 3 iter 6500 loss: 9433.251953125 tv_loss: 0.2263144701719284 norm_loss: 0.8540769815444946 task_loss: 0.00012666129623539746 loss_bn: 0.08571849763393402
task 3 iter 6600 loss: 9452.7568359375 tv_loss: 0.2261914610862732 norm_loss: 0.8540774583816528 task_loss: 0.00012498421710915864 loss_bn: 0.08768655359745026
task 3 iter 6700 loss: 9440.625 tv_loss: 0.2260543555021286 norm_loss: 0.8540739417076111 task_loss: 0.00012359206448309124 loss_bn: 0.0864921286702156
task 3 iter 6800 loss: 9429.5869140625 tv_loss: 0.22593161463737488 norm_loss: 0.854072630405426 task_loss: 0.00012240666546858847 loss_bn: 0.08540261536836624
task 3 iter 6900 loss: 9430.943359375 tv_loss: 0.2258068323135376 norm_loss: 0.8540691137313843 task_loss: 0.00012149875692557544 loss_bn: 0.0855521634221077
task 3 iter 7000 loss: 9428.345703125 tv_loss: 0.22568263113498688 norm_loss: 0.8540644645690918 task_loss: 0.00012003770098090172 loss_bn: 0.08531288802623749
task 3 iter 7100 loss: 9413.8681640625 tv_loss: 0.2255624234676361 norm_loss: 0.8540617227554321 task_loss: 0.00011897613876499236 loss_bn: 0.08387971669435501
task 3 iter 7200 loss: 9411.2421875 tv_loss: 0.22544415295124054 norm_loss: 0.8540573120117188 task_loss: 0.00011814551544375718 loss_bn: 0.0836309939622879
task 3 iter 7300 loss: 9432.58203125 tv_loss: 0.22528955340385437 norm_loss: 0.8540471792221069 task_loss: 0.00011624119360931218 loss_bn: 0.08579573780298233
task 3 iter 7400 loss: 9378.7060546875 tv_loss: 0.22514620423316956 norm_loss: 0.8540445566177368 task_loss: 0.00011400350922485813 loss_bn: 0.08043457567691803
task 3 iter 7500 loss: 9389.873046875 tv_loss: 0.22499766945838928 norm_loss: 0.854035496711731 task_loss: 0.00011250242096139118 loss_bn: 0.08157682418823242
task 3 iter 7600 loss: 9455.4287109375 tv_loss: 0.22485840320587158 norm_loss: 0.8540301322937012 task_loss: 0.0001117034480557777 loss_bn: 0.08814705163240433
task 3 iter 7700 loss: 9428.744140625 tv_loss: 0.22472690045833588 norm_loss: 0.8540263175964355 task_loss: 0.00011027404252672568 loss_bn: 0.0854981541633606
task 3 iter 7800 loss: 9393.1474609375 tv_loss: 0.22460106015205383 norm_loss: 0.8540211319923401 task_loss: 0.00010915844177361578 loss_bn: 0.08195601403713226
task 3 iter 7900 loss: 9368.765625 tv_loss: 0.22447265684604645 norm_loss: 0.8540124893188477 task_loss: 0.00010826728248503059 loss_bn: 0.07953661680221558
task 3 iter 8000 loss: 9387.8701171875 tv_loss: 0.22435423731803894 norm_loss: 0.8540055751800537 task_loss: 0.00010728021879913285 loss_bn: 0.08146514743566513
task 3 iter 8100 loss: 9370.1357421875 tv_loss: 0.22421959042549133 norm_loss: 0.853996992111206 task_loss: 0.00010624654532875866 loss_bn: 0.07971195876598358
task 3 iter 8200 loss: 9354.1513671875 tv_loss: 0.2240985929965973 norm_loss: 0.8539906144142151 task_loss: 0.00010535539331613109 loss_bn: 0.07813000679016113
task 3 iter 8300 loss: 9352.04296875 tv_loss: 0.2239835560321808 norm_loss: 0.8539841175079346 task_loss: 0.0001046132092596963 loss_bn: 0.07793422788381577
task 3 iter 8400 loss: 9344.8359375 tv_loss: 0.22387182712554932 norm_loss: 0.853976845741272 task_loss: 0.00010395205026725307 loss_bn: 0.07722846418619156
task 3 iter 8500 loss: 9342.126953125 tv_loss: 0.22376210987567902 norm_loss: 0.8539695143699646 task_loss: 0.00010334025137126446 loss_bn: 0.07697214931249619
task 3 iter 8600 loss: 9331.1435546875 tv_loss: 0.2236495018005371 norm_loss: 0.8539616465568542 task_loss: 0.00010257289977744222 loss_bn: 0.07589054852724075
task 3 iter 8700 loss: 9336.806640625 tv_loss: 0.22354888916015625 norm_loss: 0.8539561033248901 task_loss: 0.00010144427506020293 loss_bn: 0.07647475600242615
task 3 iter 8800 loss: 9321.7578125 tv_loss: 0.22343149781227112 norm_loss: 0.853949785232544 task_loss: 0.00010071327415062115 loss_bn: 0.07498461753129959
task 3 iter 8900 loss: 9402.47265625 tv_loss: 0.22332826256752014 norm_loss: 0.8539395928382874 task_loss: 0.00010013404971687123 loss_bn: 0.08307302743196487
task 3 iter 9000 loss: 9372.447265625 tv_loss: 0.22320914268493652 norm_loss: 0.8539319634437561 task_loss: 9.892254456644878e-05 loss_bn: 0.08009147644042969
task 3 iter 9100 loss: 9385.9423828125 tv_loss: 0.22309747338294983 norm_loss: 0.8539214134216309 task_loss: 9.78944735834375e-05 loss_bn: 0.08146286755800247
task 3 iter 9200 loss: 9385.1103515625 tv_loss: 0.22298750281333923 norm_loss: 0.8539115786552429 task_loss: 9.720257367007434e-05 loss_bn: 0.08139753341674805
task 3 iter 9300 loss: 9373.076171875 tv_loss: 0.22288192808628082 norm_loss: 0.8539038896560669 task_loss: 9.669039718573913e-05 loss_bn: 0.08020803332328796
task 3 iter 9400 loss: 9372.40625 tv_loss: 0.2227788269519806 norm_loss: 0.8538948893547058 task_loss: 9.619218326406553e-05 loss_bn: 0.08015595376491547
task 3 iter 9500 loss: 9362.1318359375 tv_loss: 0.22267445921897888 norm_loss: 0.8538861274719238 task_loss: 9.558409510646015e-05 loss_bn: 0.0791444256901741
task 3 iter 9600 loss: 9366.302734375 tv_loss: 0.22257208824157715 norm_loss: 0.8538748621940613 task_loss: 9.50477333390154e-05 loss_bn: 0.07957921177148819
task 3 iter 9700 loss: 9361.1787109375 tv_loss: 0.22247110307216644 norm_loss: 0.8538668751716614 task_loss: 9.466966730542481e-05 loss_bn: 0.07907956838607788
task 3 iter 9800 loss: 9318.73046875 tv_loss: 0.22235679626464844 norm_loss: 0.853851854801178 task_loss: 9.416863758815452e-05 loss_bn: 0.0748559832572937
task 3 iter 9900 loss: 9364.814453125 tv_loss: 0.22224915027618408 norm_loss: 0.8538460731506348 task_loss: 9.376728849019855e-05 loss_bn: 0.07947519421577454
task 3 iter 10000 loss: 9345.744140625 tv_loss: 0.22213229537010193 norm_loss: 0.8538371324539185 task_loss: 9.295524796471e-05 loss_bn: 0.07758643478155136
task 4 iter 100 loss: 109094.90625 tv_loss: 0.47377312183380127 norm_loss: 0.9395488500595093 task_loss: 0.023747602477669716 loss_bn: 9.727727890014648
task 4 iter 200 loss: 61026.859375 tv_loss: 0.41756653785705566 norm_loss: 0.9045248627662659 task_loss: 0.01509754080325365 loss_bn: 5.0430097579956055
task 4 iter 300 loss: 45129.87890625 tv_loss: 0.3909379541873932 norm_loss: 0.8827791213989258 task_loss: 0.011991421692073345 loss_bn: 3.506385087966919
task 4 iter 400 loss: 37245.67578125 tv_loss: 0.37355130910873413 norm_loss: 0.8720840215682983 task_loss: 0.010258704423904419 loss_bn: 2.7461612224578857
task 4 iter 500 loss: 32876.20703125 tv_loss: 0.360676646232605 norm_loss: 0.8667302131652832 task_loss: 0.009047472849488258 loss_bn: 2.3268089294433594
task 4 iter 600 loss: 29553.4765625 tv_loss: 0.35044658184051514 norm_loss: 0.863837718963623 task_loss: 0.008009877987205982 loss_bn: 2.007906913757324
task 4 iter 700 loss: 27468.56640625 tv_loss: 0.34165599942207336 norm_loss: 0.8620921969413757 task_loss: 0.0071898228488862514 loss_bn: 1.8094496726989746
task 4 iter 800 loss: 25994.15625 tv_loss: 0.3333064913749695 norm_loss: 0.8608270883560181 task_loss: 0.0066592455841600895 loss_bn: 1.6686630249023438
task 4 iter 900 loss: 24363.78515625 tv_loss: 0.32629483938217163 norm_loss: 0.8600408434867859 task_loss: 0.006204580422490835 loss_bn: 1.5110288858413696
task 4 iter 1000 loss: 22774.84765625 tv_loss: 0.3200852870941162 norm_loss: 0.8594155311584473 task_loss: 0.005786721594631672 loss_bn: 1.3570010662078857
task 4 iter 1100 loss: 20573.6484375 tv_loss: 0.31358107924461365 norm_loss: 0.8587607741355896 task_loss: 0.005537649150937796 loss_bn: 1.1400917768478394
task 4 iter 1200 loss: 20549.599609375 tv_loss: 0.30757445096969604 norm_loss: 0.8582441210746765 task_loss: 0.005259083118289709 loss_bn: 1.1410492658615112
task 4 iter 1300 loss: 19846.99609375 tv_loss: 0.3023691475391388 norm_loss: 0.8578752875328064 task_loss: 0.005102337803691626 loss_bn: 1.0727773904800415
task 4 iter 1400 loss: 19082.99609375 tv_loss: 0.29767465591430664 norm_loss: 0.8575098514556885 task_loss: 0.004793752450495958 loss_bn: 0.999875545501709
task 4 iter 1500 loss: 18024.453125 tv_loss: 0.2931627035140991 norm_loss: 0.8572177886962891 task_loss: 0.0046448009088635445 loss_bn: 0.895847737789154
task 4 iter 1600 loss: 17874.12890625 tv_loss: 0.28878068923950195 norm_loss: 0.8568588495254517 task_loss: 0.004483905155211687 loss_bn: 0.8828271627426147
task 4 iter 1700 loss: 17350.7109375 tv_loss: 0.2851365804672241 norm_loss: 0.8566683530807495 task_loss: 0.00429554982110858 loss_bn: 0.832595944404602
task 4 iter 1800 loss: 17996.484375 tv_loss: 0.28150299191474915 norm_loss: 0.8564796447753906 task_loss: 0.004149231128394604 loss_bn: 0.8988615274429321
task 4 iter 1900 loss: 17212.83203125 tv_loss: 0.2781975567340851 norm_loss: 0.8563296794891357 task_loss: 0.004060432780534029 loss_bn: 0.8215672373771667
task 4 iter 2000 loss: 17683.34375 tv_loss: 0.27490130066871643 norm_loss: 0.8561298251152039 task_loss: 0.003855140646919608 loss_bn: 0.8709040880203247
task 4 iter 2100 loss: 16053.787109375 tv_loss: 0.2718203365802765 norm_loss: 0.8559160232543945 task_loss: 0.0037812620867043734 loss_bn: 0.7089318633079529
task 4 iter 2200 loss: 16037.1669921875 tv_loss: 0.2687343955039978 norm_loss: 0.8557478189468384 task_loss: 0.0036910721100866795 loss_bn: 0.7083708047866821
task 4 iter 2300 loss: 15432.916015625 tv_loss: 0.2660652697086334 norm_loss: 0.8556066751480103 task_loss: 0.0036627163644880056 loss_bn: 0.6483972072601318
task 4 iter 2400 loss: 15594.5888671875 tv_loss: 0.2634006142616272 norm_loss: 0.8553994297981262 task_loss: 0.00358186149969697 loss_bn: 0.6656068563461304
task 4 iter 2500 loss: 15266.685546875 tv_loss: 0.2611502408981323 norm_loss: 0.8552960157394409 task_loss: 0.0035382499918341637 loss_bn: 0.6333785057067871
task 4 iter 2600 loss: 15227.0546875 tv_loss: 0.25901317596435547 norm_loss: 0.8551818132400513 task_loss: 0.003463928122073412 loss_bn: 0.6302942037582397
task 4 iter 2700 loss: 14935.7734375 tv_loss: 0.25692346692085266 norm_loss: 0.8550643920898438 task_loss: 0.003303846111521125 loss_bn: 0.6029053330421448
task 4 iter 2800 loss: 14497.919921875 tv_loss: 0.25457489490509033 norm_loss: 0.8548811078071594 task_loss: 0.0032925244886428118 loss_bn: 0.5594398379325867
task 4 iter 2900 loss: 14503.5390625 tv_loss: 0.25270992517471313 norm_loss: 0.8548004627227783 task_loss: 0.003221022430807352 loss_bn: 0.5608160495758057
task 4 iter 3000 loss: 15003.994140625 tv_loss: 0.2511993646621704 norm_loss: 0.8547698259353638 task_loss: 0.0031081940978765488 loss_bn: 0.6120355725288391
task 4 iter 3100 loss: 14495.107421875 tv_loss: 0.24922464787960052 norm_loss: 0.8545936942100525 task_loss: 0.0031014885753393173 loss_bn: 0.5614100098609924
task 4 iter 3200 loss: 13702.404296875 tv_loss: 0.24756960570812225 norm_loss: 0.8545424938201904 task_loss: 0.0029874674510210752 loss_bn: 0.4833475649356842
task 4 iter 3300 loss: 14358.52734375 tv_loss: 0.24602726101875305 norm_loss: 0.8544749617576599 task_loss: 0.0030047185719013214 loss_bn: 0.5488702654838562
task 4 iter 3400 loss: 13902.56640625 tv_loss: 0.24444815516471863 norm_loss: 0.8543772101402283 task_loss: 0.002971480367705226 loss_bn: 0.5037201642990112
task 4 iter 3500 loss: 14642.5234375 tv_loss: 0.24317654967308044 norm_loss: 0.8543716073036194 task_loss: 0.002852723700925708 loss_bn: 0.5789217352867126
task 4 iter 3600 loss: 14205.765625 tv_loss: 0.2421177178621292 norm_loss: 0.854354977607727 task_loss: 0.0028307621832937002 loss_bn: 0.5354927778244019
task 4 iter 3700 loss: 13697.1640625 tv_loss: 0.24073298275470734 norm_loss: 0.854248046875 task_loss: 0.0027656517922878265 loss_bn: 0.48540446162223816
task 4 iter 3800 loss: 13817.556640625 tv_loss: 0.23967987298965454 norm_loss: 0.8542523384094238 task_loss: 0.002750176703557372 loss_bn: 0.4976047873497009
task 4 iter 3900 loss: 13425.8076171875 tv_loss: 0.23858524858951569 norm_loss: 0.8541965484619141 task_loss: 0.0026810935232788324 loss_bn: 0.459187388420105
task 4 iter 4000 loss: 13446.1298828125 tv_loss: 0.2375769317150116 norm_loss: 0.8541445732116699 task_loss: 0.0026338298339396715 loss_bn: 0.4617544114589691
task 4 iter 4100 loss: 13646.45703125 tv_loss: 0.23689855635166168 norm_loss: 0.8542071580886841 task_loss: 0.0026118962559849024 loss_bn: 0.4819505512714386
task 4 iter 4200 loss: 13304.763671875 tv_loss: 0.2359301745891571 norm_loss: 0.8541924953460693 task_loss: 0.0026027746498584747 loss_bn: 0.4478968381881714
task 4 iter 4300 loss: 13829.3603515625 tv_loss: 0.23493772745132446 norm_loss: 0.8541141748428345 task_loss: 0.002606807742267847 loss_bn: 0.500404417514801
task 4 iter 4400 loss: 13218.197265625 tv_loss: 0.2342393845319748 norm_loss: 0.8541025519371033 task_loss: 0.002520926296710968 loss_bn: 0.4401654601097107
task 4 iter 4500 loss: 13287.146484375 tv_loss: 0.23363754153251648 norm_loss: 0.8541322946548462 task_loss: 0.00244722468778491 loss_bn: 0.4477737843990326
task 4 iter 4600 loss: 14464.3828125 tv_loss: 0.23260429501533508 norm_loss: 0.8540633916854858 task_loss: 0.0024950748775154352 loss_bn: 0.5650981664657593
task 4 iter 4700 loss: 14451.912109375 tv_loss: 0.23193690180778503 norm_loss: 0.8540570735931396 task_loss: 0.002409454667940736 loss_bn: 0.5647202730178833
task 4 iter 4800 loss: 13557.74609375 tv_loss: 0.2317153811454773 norm_loss: 0.8541353344917297 task_loss: 0.0023588037583976984 loss_bn: 0.47573408484458923
task 4 iter 4900 loss: 13487.37890625 tv_loss: 0.2310982346534729 norm_loss: 0.8540905714035034 task_loss: 0.002312701428309083 loss_bn: 0.46920934319496155
task 4 iter 5000 loss: 13708.26953125 tv_loss: 0.23049435019493103 norm_loss: 0.854073166847229 task_loss: 0.0022552201990038157 loss_bn: 0.4918966293334961
task 4 iter 5100 loss: 9756.375 tv_loss: 0.23004812002182007 norm_loss: 0.8539820909500122 task_loss: 0.002264106646180153 loss_bn: 0.09671386331319809
task 4 iter 5200 loss: 9728.3486328125 tv_loss: 0.22983109951019287 norm_loss: 0.8539677858352661 task_loss: 0.0022193260956555605 loss_bn: 0.09437551349401474
task 4 iter 5300 loss: 9695.6533203125 tv_loss: 0.22964750230312347 norm_loss: 0.853958249092102 task_loss: 0.002185529563575983 loss_bn: 0.09145534783601761
task 4 iter 5400 loss: 9669.8212890625 tv_loss: 0.22947630286216736 norm_loss: 0.8539517521858215 task_loss: 0.002157837152481079 loss_bn: 0.08915718644857407
task 4 iter 5500 loss: 9682.259765625 tv_loss: 0.22932395339012146 norm_loss: 0.853954553604126 task_loss: 0.002119992859661579 loss_bn: 0.09077820181846619
task 4 iter 5600 loss: 9657.3876953125 tv_loss: 0.22918330132961273 norm_loss: 0.8539669513702393 task_loss: 0.002091940026730299 loss_bn: 0.0885605588555336
task 4 iter 5700 loss: 9638.5478515625 tv_loss: 0.22905436158180237 norm_loss: 0.8539782166481018 task_loss: 0.0020693137776106596 loss_bn: 0.08689291030168533
task 4 iter 5800 loss: 9650.962890625 tv_loss: 0.22892287373542786 norm_loss: 0.853987991809845 task_loss: 0.0020530575420707464 loss_bn: 0.08828850835561752
task 4 iter 5900 loss: 9635.8134765625 tv_loss: 0.2287966012954712 norm_loss: 0.8539979457855225 task_loss: 0.002033115131780505 loss_bn: 0.08696425706148148
task 4 iter 6000 loss: 9638.0888671875 tv_loss: 0.2286740243434906 norm_loss: 0.8540065288543701 task_loss: 0.002014671452343464 loss_bn: 0.08736887574195862
task 4 iter 6100 loss: 9627.734375 tv_loss: 0.22855374217033386 norm_loss: 0.8540143966674805 task_loss: 0.001995983999222517 loss_bn: 0.08651366829872131
task 4 iter 6200 loss: 9628.529296875 tv_loss: 0.22842121124267578 norm_loss: 0.8540154695510864 task_loss: 0.0019801862072199583 loss_bn: 0.08675146102905273
task 4 iter 6300 loss: 9615.970703125 tv_loss: 0.22829899191856384 norm_loss: 0.8540240526199341 task_loss: 0.001964128576219082 loss_bn: 0.08564874529838562
task 4 iter 6400 loss: 9617.6025390625 tv_loss: 0.22817948460578918 norm_loss: 0.854033350944519 task_loss: 0.0019500725902616978 loss_bn: 0.08594433218240738
task 4 iter 6500 loss: 9598.0419921875 tv_loss: 0.22807690501213074 norm_loss: 0.8540385961532593 task_loss: 0.0019357751589268446 loss_bn: 0.08412710577249527
task 4 iter 6600 loss: 9593.4462890625 tv_loss: 0.22795888781547546 norm_loss: 0.8540407419204712 task_loss: 0.0019216317450627685 loss_bn: 0.0838080421090126
task 4 iter 6700 loss: 9563.857421875 tv_loss: 0.2278468906879425 norm_loss: 0.8540436625480652 task_loss: 0.0019086531829088926 loss_bn: 0.08097700029611588
task 4 iter 6800 loss: 9665.923828125 tv_loss: 0.22769847512245178 norm_loss: 0.8540471792221069 task_loss: 0.0018881810829043388 loss_bn: 0.09138638526201248
task 4 iter 6900 loss: 9615.453125 tv_loss: 0.22757554054260254 norm_loss: 0.8540523052215576 task_loss: 0.0018686001421883702 loss_bn: 0.08653123676776886
task 4 iter 7000 loss: 9603.7822265625 tv_loss: 0.22746095061302185 norm_loss: 0.8540566563606262 task_loss: 0.0018534312257543206 loss_bn: 0.08551272004842758
task 4 iter 7100 loss: 9564.2578125 tv_loss: 0.22733795642852783 norm_loss: 0.8540588617324829 task_loss: 0.0018369791796430945 loss_bn: 0.08172376453876495
task 4 iter 7200 loss: 9685.9150390625 tv_loss: 0.22723844647407532 norm_loss: 0.8540657758712769 task_loss: 0.0018227266846224666 loss_bn: 0.09402605146169662
task 4 iter 7300 loss: 9668.50390625 tv_loss: 0.22710826992988586 norm_loss: 0.8540661334991455 task_loss: 0.0018095369450747967 loss_bn: 0.09241791069507599
task 4 iter 7400 loss: 9672.0810546875 tv_loss: 0.2270035743713379 norm_loss: 0.8540645837783813 task_loss: 0.0017973636277019978 loss_bn: 0.0928998813033104
task 4 iter 7500 loss: 9653.8017578125 tv_loss: 0.22688791155815125 norm_loss: 0.8540642261505127 task_loss: 0.0017857187194749713 loss_bn: 0.09118987619876862
task 4 iter 7600 loss: 9658.6142578125 tv_loss: 0.22677525877952576 norm_loss: 0.8540631532669067 task_loss: 0.001775402924977243 loss_bn: 0.09177643060684204
task 4 iter 7700 loss: 9631.9580078125 tv_loss: 0.226669579744339 norm_loss: 0.8540626168251038 task_loss: 0.0017666525673121214 loss_bn: 0.08920001238584518
task 4 iter 7800 loss: 9628.69140625 tv_loss: 0.22655004262924194 norm_loss: 0.8540565967559814 task_loss: 0.0017590726492926478 loss_bn: 0.08895624428987503
task 4 iter 7900 loss: 9617.9423828125 tv_loss: 0.22644931077957153 norm_loss: 0.8540552854537964 task_loss: 0.001749849645420909 loss_bn: 0.08797596395015717
task 4 iter 8000 loss: 9621.1796875 tv_loss: 0.22635528445243835 norm_loss: 0.8540549874305725 task_loss: 0.0017417611088603735 loss_bn: 0.0883818119764328
task 4 iter 8100 loss: 9610.5927734375 tv_loss: 0.22625625133514404 norm_loss: 0.8540554046630859 task_loss: 0.0017342671053484082 loss_bn: 0.08739861845970154
task 4 iter 8200 loss: 9590.125 tv_loss: 0.2261638641357422 norm_loss: 0.8540530204772949 task_loss: 0.0017263913759961724 loss_bn: 0.08543392270803452
task 4 iter 8300 loss: 9620.2080078125 tv_loss: 0.22603297233581543 norm_loss: 0.8540424108505249 task_loss: 0.0017237531719729304 loss_bn: 0.08848057687282562
task 4 iter 8400 loss: 9611.5537109375 tv_loss: 0.2259300798177719 norm_loss: 0.854042649269104 task_loss: 0.0017130110645666718 loss_bn: 0.0877232700586319
task 4 iter 8500 loss: 9603.087890625 tv_loss: 0.22583352029323578 norm_loss: 0.8540396690368652 task_loss: 0.001705953967757523 loss_bn: 0.08695123344659805
task 4 iter 8600 loss: 9584.0615234375 tv_loss: 0.22573909163475037 norm_loss: 0.8540371656417847 task_loss: 0.0016977273626253009 loss_bn: 0.08513431251049042
task 4 iter 8700 loss: 9581.1728515625 tv_loss: 0.2256476879119873 norm_loss: 0.8540350198745728 task_loss: 0.0016908117104321718 loss_bn: 0.08491770923137665
task 4 iter 8800 loss: 9591.6015625 tv_loss: 0.2255445122718811 norm_loss: 0.8540257215499878 task_loss: 0.0016846460057422519 loss_bn: 0.08603262901306152
task 4 iter 8900 loss: 9591.7021484375 tv_loss: 0.2254577875137329 norm_loss: 0.8540257811546326 task_loss: 0.0016765865730121732 loss_bn: 0.0861240103840828
task 4 iter 9000 loss: 9583.498046875 tv_loss: 0.22536849975585938 norm_loss: 0.854022741317749 task_loss: 0.0016696476377546787 loss_bn: 0.08537683635950089
task 4 iter 9100 loss: 9572.59375 tv_loss: 0.2252766638994217 norm_loss: 0.854019284248352 task_loss: 0.0016643361886963248 loss_bn: 0.08434399962425232
task 4 iter 9200 loss: 9558.30859375 tv_loss: 0.2251872420310974 norm_loss: 0.8540178537368774 task_loss: 0.001661089714616537 loss_bn: 0.08295022696256638
task 4 iter 9300 loss: 9538.82421875 tv_loss: 0.22508913278579712 norm_loss: 0.8540122509002686 task_loss: 0.0016542916418984532 loss_bn: 0.08107631653547287
task 4 iter 9400 loss: 9604.572265625 tv_loss: 0.22496598958969116 norm_loss: 0.8539963960647583 task_loss: 0.0016484918305650353 loss_bn: 0.08772625029087067
task 4 iter 9500 loss: 9563.19921875 tv_loss: 0.2248738408088684 norm_loss: 0.8539944887161255 task_loss: 0.0016391994431614876 loss_bn: 0.08368467539548874
task 4 iter 9600 loss: 9531.4287109375 tv_loss: 0.22478866577148438 norm_loss: 0.8539910316467285 task_loss: 0.0016321447910740972 loss_bn: 0.08058249205350876
task 4 iter 9700 loss: 9522.95703125 tv_loss: 0.2247030884027481 norm_loss: 0.8539835810661316 task_loss: 0.0016257257666438818 loss_bn: 0.07980785518884659
task 4 iter 9800 loss: 9517.66796875 tv_loss: 0.22461029887199402 norm_loss: 0.853981614112854 task_loss: 0.001619938062503934 loss_bn: 0.07933962345123291
task 4 iter 9900 loss: 9499.3134765625 tv_loss: 0.22452571988105774 norm_loss: 0.8539770841598511 task_loss: 0.0016136288177222013 loss_bn: 0.0775727927684784
task 4 iter 10000 loss: 9495.8544921875 tv_loss: 0.22444838285446167 norm_loss: 0.8539703488349915 task_loss: 0.0016075546154752374 loss_bn: 0.07729513943195343
task 5 iter 100 loss: 98989.6796875 tv_loss: 0.4667336344718933 norm_loss: 0.9368807077407837 task_loss: 0.02419278211891651 loss_bn: 8.715492248535156
task 5 iter 200 loss: 55311.0625 tv_loss: 0.41213905811309814 norm_loss: 0.8998267650604248 task_loss: 0.015246082097291946 loss_bn: 4.474697113037109
task 5 iter 300 loss: 40841.453125 tv_loss: 0.3863410949707031 norm_loss: 0.8791981339454651 task_loss: 0.012336724437773228 loss_bn: 3.07771635055542
task 5 iter 400 loss: 33785.16015625 tv_loss: 0.3696710467338562 norm_loss: 0.869796633720398 task_loss: 0.010542013682425022 loss_bn: 2.3996024131774902
task 5 iter 500 loss: 29168.76953125 tv_loss: 0.35742419958114624 norm_loss: 0.8652689456939697 task_loss: 0.009173261001706123 loss_bn: 1.956301212310791
task 5 iter 600 loss: 26598.10546875 tv_loss: 0.3476408123970032 norm_loss: 0.8627862334251404 task_loss: 0.008256484754383564 loss_bn: 1.7109830379486084
task 5 iter 700 loss: 24419.96875 tv_loss: 0.33914780616760254 norm_loss: 0.8612034916877747 task_loss: 0.007559114135801792 loss_bn: 1.5018106698989868
task 5 iter 800 loss: 22598.96875 tv_loss: 0.3315357565879822 norm_loss: 0.8601480722427368 task_loss: 0.00704906927421689 loss_bn: 1.3259427547454834
task 5 iter 900 loss: 21391.900390625 tv_loss: 0.32452958822250366 norm_loss: 0.8593802452087402 task_loss: 0.00662249606102705 loss_bn: 1.2103395462036133
task 5 iter 1000 loss: 20638.685546875 tv_loss: 0.3180738687515259 norm_loss: 0.8588123321533203 task_loss: 0.006281808018684387 loss_bn: 1.1390573978424072
task 5 iter 1100 loss: 19170.1171875 tv_loss: 0.3113801181316376 norm_loss: 0.8581869006156921 task_loss: 0.006029712967574596 loss_bn: 0.9954137802124023
task 5 iter 1200 loss: 18542.375 tv_loss: 0.305630624294281 norm_loss: 0.857714056968689 task_loss: 0.005713855382055044 loss_bn: 0.936328649520874
task 5 iter 1300 loss: 17646.69140625 tv_loss: 0.30043524503707886 norm_loss: 0.8573294878005981 task_loss: 0.005439596716314554 loss_bn: 0.8499394059181213
task 5 iter 1400 loss: 17359.6015625 tv_loss: 0.29534876346588135 norm_loss: 0.8569727540016174 task_loss: 0.005307856015861034 loss_bn: 0.8229554295539856
task 5 iter 1500 loss: 16573.806640625 tv_loss: 0.29046258330345154 norm_loss: 0.8566268086433411 task_loss: 0.004962418228387833 loss_bn: 0.7482250332832336
task 5 iter 1600 loss: 16206.810546875 tv_loss: 0.2860454320907593 norm_loss: 0.8563263416290283 task_loss: 0.00475957291200757 loss_bn: 0.7138984799385071
task 5 iter 1700 loss: 17621.1015625 tv_loss: 0.2822442054748535 norm_loss: 0.8561292886734009 task_loss: 0.004669233225286007 loss_bn: 0.8564661741256714
task 5 iter 1800 loss: 16698.953125 tv_loss: 0.2786417603492737 norm_loss: 0.8558874130249023 task_loss: 0.004549640696495771 loss_bn: 0.7657251954078674
task 5 iter 1900 loss: 16758.736328125 tv_loss: 0.27542221546173096 norm_loss: 0.8557231426239014 task_loss: 0.0044593410566449165 loss_bn: 0.7728027701377869
task 5 iter 2000 loss: 15703.8974609375 tv_loss: 0.2725561559200287 norm_loss: 0.8555629849433899 task_loss: 0.00424885842949152 loss_bn: 0.6696125864982605
task 5 iter 2100 loss: 16737.80078125 tv_loss: 0.26974159479141235 norm_loss: 0.8553949594497681 task_loss: 0.004218957386910915 loss_bn: 0.7734981179237366
task 5 iter 2200 loss: 14962.1630859375 tv_loss: 0.2671750485897064 norm_loss: 0.8552619814872742 task_loss: 0.0041859447956085205 loss_bn: 0.5964231491088867
task 5 iter 2300 loss: 15262.609375 tv_loss: 0.2644761800765991 norm_loss: 0.8551496267318726 task_loss: 0.003984950948506594 loss_bn: 0.6286170482635498
task 5 iter 2400 loss: 15277.642578125 tv_loss: 0.26203566789627075 norm_loss: 0.8550219535827637 task_loss: 0.003941360395401716 loss_bn: 0.6307083368301392
task 5 iter 2500 loss: 15742.3984375 tv_loss: 0.2597987949848175 norm_loss: 0.8548785448074341 task_loss: 0.0039059806149452925 loss_bn: 0.6777035593986511
task 5 iter 2600 loss: 15477.44921875 tv_loss: 0.2577017545700073 norm_loss: 0.8547744154930115 task_loss: 0.0037827761843800545 loss_bn: 0.6525657773017883
task 5 iter 2700 loss: 15644.0859375 tv_loss: 0.2555866837501526 norm_loss: 0.8546220064163208 task_loss: 0.0037381851579993963 loss_bn: 0.6698488593101501
task 5 iter 2800 loss: 14588.962890625 tv_loss: 0.2537900507450104 norm_loss: 0.8545917868614197 task_loss: 0.0036783937830477953 loss_bn: 0.5649825930595398
task 5 iter 2900 loss: 15274.94140625 tv_loss: 0.2517605721950531 norm_loss: 0.854424238204956 task_loss: 0.0037000500597059727 loss_bn: 0.6335518956184387
task 5 iter 3000 loss: 14596.9140625 tv_loss: 0.2501372694969177 norm_loss: 0.8543208837509155 task_loss: 0.00359039637260139 loss_bn: 0.5669651031494141
task 5 iter 3100 loss: 14239.265625 tv_loss: 0.24855047464370728 norm_loss: 0.8542487025260925 task_loss: 0.0035292308311909437 loss_bn: 0.5318999290466309
task 5 iter 3200 loss: 15045.7275390625 tv_loss: 0.24729035794734955 norm_loss: 0.854202389717102 task_loss: 0.0034652194008231163 loss_bn: 0.6132453083992004
task 5 iter 3300 loss: 13994.51953125 tv_loss: 0.2457161694765091 norm_loss: 0.8540812730789185 task_loss: 0.003390443976968527 loss_bn: 0.509009063243866
task 5 iter 3400 loss: 14310.25390625 tv_loss: 0.2445949912071228 norm_loss: 0.8540991544723511 task_loss: 0.0033524618484079838 loss_bn: 0.540955662727356
task 5 iter 3500 loss: 14229.107421875 tv_loss: 0.24300506711006165 norm_loss: 0.8539472818374634 task_loss: 0.0033500713761895895 loss_bn: 0.5330326557159424
task 5 iter 3600 loss: 13940.3984375 tv_loss: 0.24176804721355438 norm_loss: 0.8539336323738098 task_loss: 0.0032855498138815165 loss_bn: 0.5048330426216125
task 5 iter 3700 loss: 13054.5234375 tv_loss: 0.24043649435043335 norm_loss: 0.8538238406181335 task_loss: 0.0031197990756481886 loss_bn: 0.4180261194705963
task 5 iter 3800 loss: 13894.513671875 tv_loss: 0.2392834722995758 norm_loss: 0.853844165802002 task_loss: 0.00313748512417078 loss_bn: 0.5018395185470581
task 5 iter 3900 loss: 14532.4296875 tv_loss: 0.23839816451072693 norm_loss: 0.8538089990615845 task_loss: 0.0031253574416041374 loss_bn: 0.5657963156700134
task 5 iter 4000 loss: 14330.455078125 tv_loss: 0.2373492568731308 norm_loss: 0.8537842035293579 task_loss: 0.003106247866526246 loss_bn: 0.5458253622055054
task 5 iter 4100 loss: 13711.4775390625 tv_loss: 0.23664972186088562 norm_loss: 0.8537613153457642 task_loss: 0.0030138478614389896 loss_bn: 0.4848814606666565
task 5 iter 4200 loss: 13475.1787109375 tv_loss: 0.23575963079929352 norm_loss: 0.8537558317184448 task_loss: 0.002948015695437789 loss_bn: 0.4619241952896118
task 5 iter 4300 loss: 14043.544921875 tv_loss: 0.23528751730918884 norm_loss: 0.8538413047790527 task_loss: 0.002917192643508315 loss_bn: 0.518988311290741
task 5 iter 4400 loss: 13542.759765625 tv_loss: 0.23467525839805603 norm_loss: 0.8538192510604858 task_loss: 0.002849070355296135 loss_bn: 0.4696193039417267
task 5 iter 4500 loss: 13476.0166015625 tv_loss: 0.23347072303295135 norm_loss: 0.8536934852600098 task_loss: 0.0028449802193790674 loss_bn: 0.46312370896339417
task 5 iter 4600 loss: 14293.15625 tv_loss: 0.2329171895980835 norm_loss: 0.8537116050720215 task_loss: 0.002849553246051073 loss_bn: 0.544779360294342
task 5 iter 4700 loss: 13502.3818359375 tv_loss: 0.23228031396865845 norm_loss: 0.8537095785140991 task_loss: 0.0028056108858436346 loss_bn: 0.4661496877670288
task 5 iter 4800 loss: 13170.91796875 tv_loss: 0.23193442821502686 norm_loss: 0.8537360429763794 task_loss: 0.0027367817237973213 loss_bn: 0.4336685836315155
task 5 iter 4900 loss: 13810.6015625 tv_loss: 0.2315288484096527 norm_loss: 0.85374915599823 task_loss: 0.0026720676105469465 loss_bn: 0.49827516078948975
task 5 iter 5000 loss: 13565.00390625 tv_loss: 0.2310493439435959 norm_loss: 0.8537715673446655 task_loss: 0.0026422457303851843 loss_bn: 0.4739959239959717
task 5 iter 5100 loss: 9824.1943359375 tv_loss: 0.23050269484519958 norm_loss: 0.8536560535430908 task_loss: 0.002611615229398012 loss_bn: 0.10034215450286865
task 5 iter 5200 loss: 9766.537109375 tv_loss: 0.23027744889259338 norm_loss: 0.8536425828933716 task_loss: 0.002564268885180354 loss_bn: 0.0950656607747078
task 5 iter 5300 loss: 9750.9814453125 tv_loss: 0.2301115095615387 norm_loss: 0.8536384701728821 task_loss: 0.002526308875530958 loss_bn: 0.09389551728963852
task 5 iter 5400 loss: 9760.859375 tv_loss: 0.2299443781375885 norm_loss: 0.8536367416381836 task_loss: 0.002496094675734639 loss_bn: 0.09518886357545853
task 5 iter 5500 loss: 9724.5 tv_loss: 0.22980695962905884 norm_loss: 0.8536401987075806 task_loss: 0.002464315854012966 loss_bn: 0.09186854958534241
task 5 iter 5600 loss: 9718.5224609375 tv_loss: 0.22967779636383057 norm_loss: 0.8536492586135864 task_loss: 0.002438929630443454 loss_bn: 0.09151695668697357
task 5 iter 5700 loss: 9679.0751953125 tv_loss: 0.22955110669136047 norm_loss: 0.8536622524261475 task_loss: 0.0024135722778737545 loss_bn: 0.087814100086689
task 5 iter 5800 loss: 9684.87890625 tv_loss: 0.2294197380542755 norm_loss: 0.8536706566810608 task_loss: 0.0023887972347438335 loss_bn: 0.08863505721092224
task 5 iter 5900 loss: 9676.0986328125 tv_loss: 0.2292899191379547 norm_loss: 0.8536832928657532 task_loss: 0.0023672920651733875 loss_bn: 0.08796077966690063
task 5 iter 6000 loss: 9657.2294921875 tv_loss: 0.22917333245277405 norm_loss: 0.8536971211433411 task_loss: 0.0023468867875635624 loss_bn: 0.08626509457826614
task 5 iter 6100 loss: 9669.5009765625 tv_loss: 0.22904515266418457 norm_loss: 0.8537061214447021 task_loss: 0.0023281380999833345 loss_bn: 0.08767209202051163
task 5 iter 6200 loss: 9649.9833984375 tv_loss: 0.2289295196533203 norm_loss: 0.8537163138389587 task_loss: 0.0023116208612918854 loss_bn: 0.08587651699781418
task 5 iter 6300 loss: 9646.4462890625 tv_loss: 0.22882211208343506 norm_loss: 0.8537247180938721 task_loss: 0.0022978810593485832 loss_bn: 0.08565296232700348
task 5 iter 6400 loss: 9633.408203125 tv_loss: 0.22871896624565125 norm_loss: 0.8537311553955078 task_loss: 0.0022845356725156307 loss_bn: 0.08447717875242233
task 5 iter 6500 loss: 9625.5546875 tv_loss: 0.22861848771572113 norm_loss: 0.8537377119064331 task_loss: 0.0022727870382368565 loss_bn: 0.08380375057458878
task 5 iter 6600 loss: 9615.849609375 tv_loss: 0.22852018475532532 norm_loss: 0.8537448644638062 task_loss: 0.002260569715872407 loss_bn: 0.08294926583766937
task 5 iter 6700 loss: 9621.3662109375 tv_loss: 0.22841672599315643 norm_loss: 0.8537479043006897 task_loss: 0.0022474199067801237 loss_bn: 0.08363030105829239
task 5 iter 6800 loss: 9623.080078125 tv_loss: 0.22830748558044434 norm_loss: 0.853750467300415 task_loss: 0.002230999292805791 loss_bn: 0.08396443724632263
task 5 iter 6900 loss: 9710.68359375 tv_loss: 0.22816675901412964 norm_loss: 0.8537525534629822 task_loss: 0.002211400307714939 loss_bn: 0.09292007982730865
task 5 iter 7000 loss: 9647.1787109375 tv_loss: 0.22804494202136993 norm_loss: 0.8537592887878418 task_loss: 0.00218806485645473 loss_bn: 0.08679749816656113
task 5 iter 7100 loss: 9694.173828125 tv_loss: 0.2279377579689026 norm_loss: 0.8537655472755432 task_loss: 0.002167966216802597 loss_bn: 0.0916927307844162
task 5 iter 7200 loss: 9631.3203125 tv_loss: 0.2278055101633072 norm_loss: 0.8537700176239014 task_loss: 0.002148612169548869 loss_bn: 0.08559788763523102
task 5 iter 7300 loss: 9595.18359375 tv_loss: 0.22768458724021912 norm_loss: 0.8537712097167969 task_loss: 0.0021330115851014853 loss_bn: 0.08214028179645538
task 5 iter 7400 loss: 9677.9873046875 tv_loss: 0.2275868058204651 norm_loss: 0.8537776470184326 task_loss: 0.0021187670063227415 loss_bn: 0.09055747836828232
task 5 iter 7500 loss: 9655.2802734375 tv_loss: 0.2274743914604187 norm_loss: 0.8537813425064087 task_loss: 0.0021017093677073717 loss_bn: 0.08845487236976624
task 5 iter 7600 loss: 9655.8046875 tv_loss: 0.22736787796020508 norm_loss: 0.8537824749946594 task_loss: 0.00209056306630373 loss_bn: 0.0886186882853508
task 5 iter 7700 loss: 9632.7734375 tv_loss: 0.2272620052099228 norm_loss: 0.8537834882736206 task_loss: 0.0020798007026314735 loss_bn: 0.08642322570085526
task 5 iter 7800 loss: 9619.0244140625 tv_loss: 0.22716157138347626 norm_loss: 0.853783905506134 task_loss: 0.0020705116912722588 loss_bn: 0.08514179289340973
task 5 iter 7900 loss: 9604.5126953125 tv_loss: 0.22706305980682373 norm_loss: 0.8537837266921997 task_loss: 0.002062226878479123 loss_bn: 0.08377472311258316
task 5 iter 8000 loss: 9582.7607421875 tv_loss: 0.2269555926322937 norm_loss: 0.8537827730178833 task_loss: 0.0020531746558845043 loss_bn: 0.08169201761484146
task 5 iter 8100 loss: 9629.6103515625 tv_loss: 0.22682929039001465 norm_loss: 0.853774905204773 task_loss: 0.002048441441729665 loss_bn: 0.08643340319395065
task 5 iter 8200 loss: 9608.21875 tv_loss: 0.22672820091247559 norm_loss: 0.8537745475769043 task_loss: 0.00203562225215137 loss_bn: 0.08442379534244537
task 5 iter 8300 loss: 9593.5263671875 tv_loss: 0.2266295850276947 norm_loss: 0.8537746071815491 task_loss: 0.0020265462808310986 loss_bn: 0.08304627984762192
task 5 iter 8400 loss: 9580.134765625 tv_loss: 0.22653496265411377 norm_loss: 0.85377436876297 task_loss: 0.0020188975613564253 loss_bn: 0.08178475499153137
task 5 iter 8500 loss: 9579.46484375 tv_loss: 0.2264440804719925 norm_loss: 0.8537734746932983 task_loss: 0.0020122434943914413 loss_bn: 0.08178608119487762
task 5 iter 8600 loss: 9567.279296875 tv_loss: 0.22635406255722046 norm_loss: 0.8537707924842834 task_loss: 0.002005847403779626 loss_bn: 0.0806351900100708
task 5 iter 8700 loss: 9577.197265625 tv_loss: 0.22626157104969025 norm_loss: 0.8537681102752686 task_loss: 0.0020004056859761477 loss_bn: 0.08168497681617737
task 5 iter 8800 loss: 9493.9345703125 tv_loss: 0.2261345088481903 norm_loss: 0.853753387928009 task_loss: 0.001990796532481909 loss_bn: 0.07347068935632706
task 5 iter 8900 loss: 9469.4296875 tv_loss: 0.22602996230125427 norm_loss: 0.8537527322769165 task_loss: 0.0019813459366559982 loss_bn: 0.07111649215221405
task 5 iter 9000 loss: 9459.0341796875 tv_loss: 0.22592653334140778 norm_loss: 0.8537537455558777 task_loss: 0.001972395461052656 loss_bn: 0.07016649097204208
task 5 iter 9100 loss: 9635.7080078125 tv_loss: 0.2258378565311432 norm_loss: 0.8537564277648926 task_loss: 0.0019679900724440813 loss_bn: 0.08787602931261063
task 5 iter 9200 loss: 9606.3056640625 tv_loss: 0.22572314739227295 norm_loss: 0.8537522554397583 task_loss: 0.0019573515746742487 loss_bn: 0.08504760265350342
task 5 iter 9300 loss: 9590.5068359375 tv_loss: 0.22562843561172485 norm_loss: 0.8537505865097046 task_loss: 0.0019481641938909888 loss_bn: 0.08356219530105591
task 5 iter 9400 loss: 9576.2578125 tv_loss: 0.22553637623786926 norm_loss: 0.8537477850914001 task_loss: 0.001940670539624989 loss_bn: 0.08221590518951416
task 5 iter 9500 loss: 9565.8212890625 tv_loss: 0.22544804215431213 norm_loss: 0.8537455797195435 task_loss: 0.0019341259030625224 loss_bn: 0.08124083280563354
task 5 iter 9600 loss: 9557.50390625 tv_loss: 0.22536621987819672 norm_loss: 0.8537428379058838 task_loss: 0.001927454024553299 loss_bn: 0.08047928661108017
task 5 iter 9700 loss: 9547.36328125 tv_loss: 0.2252797782421112 norm_loss: 0.8537397384643555 task_loss: 0.001921354909427464 loss_bn: 0.0795302540063858
task 5 iter 9800 loss: 9559.2421875 tv_loss: 0.2252151370048523 norm_loss: 0.8537395596504211 task_loss: 0.0019108273554593325 loss_bn: 0.08082419633865356
task 5 iter 9900 loss: 9551.92578125 tv_loss: 0.2251264452934265 norm_loss: 0.8537356853485107 task_loss: 0.001905251992866397 loss_bn: 0.08015310764312744
task 5 iter 10000 loss: 9545.857421875 tv_loss: 0.2250337302684784 norm_loss: 0.8537310361862183 task_loss: 0.001901553594507277 loss_bn: 0.07958875596523285
task 6 iter 100 loss: 101288.34375 tv_loss: 0.4691852331161499 norm_loss: 0.9369789361953735 task_loss: 0.024519750848412514 loss_bn: 8.94196605682373
task 6 iter 200 loss: 56070.06640625 tv_loss: 0.41316497325897217 norm_loss: 0.9002538323402405 task_loss: 0.015149161219596863 loss_bn: 4.5511298179626465
task 6 iter 300 loss: 40827.23828125 tv_loss: 0.3872052729129791 norm_loss: 0.8796496391296387 task_loss: 0.012360791675746441 loss_bn: 3.075594186782837
task 6 iter 400 loss: 33472.98046875 tv_loss: 0.37059712409973145 norm_loss: 0.8701459765434265 task_loss: 0.010414919815957546 loss_bn: 2.3692967891693115
task 6 iter 500 loss: 29625.77734375 tv_loss: 0.35820913314819336 norm_loss: 0.8656079173088074 task_loss: 0.00912917498499155 loss_bn: 2.002096176147461
task 6 iter 600 loss: 26805.82421875 tv_loss: 0.34835246205329895 norm_loss: 0.8631342649459839 task_loss: 0.008077101781964302 loss_bn: 1.7331936359405518
task 6 iter 700 loss: 24566.607421875 tv_loss: 0.3396810293197632 norm_loss: 0.8616061210632324 task_loss: 0.007447411306202412 loss_bn: 1.5171836614608765
task 6 iter 800 loss: 23285.15234375 tv_loss: 0.33205950260162354 norm_loss: 0.8606045246124268 task_loss: 0.006916499231010675 loss_bn: 1.3954250812530518
task 6 iter 900 loss: 22537.640625 tv_loss: 0.32468172907829285 norm_loss: 0.8597614169120789 task_loss: 0.0064082094468176365 loss_bn: 1.3266737461090088
task 6 iter 1000 loss: 20021.998046875 tv_loss: 0.3175384998321533 norm_loss: 0.8590925335884094 task_loss: 0.005815216340124607 loss_bn: 1.0817797183990479
task 6 iter 1100 loss: 19379.97265625 tv_loss: 0.31144940853118896 norm_loss: 0.8585976362228394 task_loss: 0.005530629772692919 loss_bn: 1.0209788084030151
task 6 iter 1200 loss: 18344.78515625 tv_loss: 0.3056821823120117 norm_loss: 0.858189046382904 task_loss: 0.005248409695923328 loss_bn: 0.9207486510276794
task 6 iter 1300 loss: 17325.873046875 tv_loss: 0.3004456162452698 norm_loss: 0.8577994704246521 task_loss: 0.0050134616903960705 loss_bn: 0.8216487169265747
task 6 iter 1400 loss: 17037.845703125 tv_loss: 0.2956695258617401 norm_loss: 0.8574916124343872 task_loss: 0.004837492015212774 loss_bn: 0.7949613332748413
task 6 iter 1500 loss: 16593.28515625 tv_loss: 0.29119396209716797 norm_loss: 0.8572158813476562 task_loss: 0.004647646564990282 loss_bn: 0.7527241110801697
task 6 iter 1600 loss: 16047.31640625 tv_loss: 0.2864915728569031 norm_loss: 0.8568620681762695 task_loss: 0.004480044357478619 loss_bn: 0.7002041339874268
task 6 iter 1700 loss: 15679.197265625 tv_loss: 0.2823490798473358 norm_loss: 0.8566533327102661 task_loss: 0.0043306066654622555 loss_bn: 0.6651368737220764
task 6 iter 1800 loss: 15107.81640625 tv_loss: 0.2784497141838074 norm_loss: 0.8564404249191284 task_loss: 0.004067801404744387 loss_bn: 0.6108787655830383
task 6 iter 1900 loss: 17469.869140625 tv_loss: 0.2751940190792084 norm_loss: 0.85631263256073 task_loss: 0.004092495422810316 loss_bn: 0.8469974994659424
task 6 iter 2000 loss: 16955.314453125 tv_loss: 0.27237027883529663 norm_loss: 0.856182336807251 task_loss: 0.0040215011686086655 loss_bn: 0.7964103817939758
task 6 iter 2100 loss: 16080.4462890625 tv_loss: 0.26963138580322266 norm_loss: 0.8560258150100708 task_loss: 0.0038507282733917236 loss_bn: 0.7108152508735657
task 6 iter 2200 loss: 17030.76953125 tv_loss: 0.2667365074157715 norm_loss: 0.8558139204978943 task_loss: 0.0038798204623162746 loss_bn: 0.8057975769042969
task 6 iter 2300 loss: 16399.01171875 tv_loss: 0.26415616273880005 norm_loss: 0.8556691408157349 task_loss: 0.0038240619469434023 loss_bn: 0.7433497905731201
task 6 iter 2400 loss: 14916.97265625 tv_loss: 0.2620236575603485 norm_loss: 0.8555426597595215 task_loss: 0.0036009633913636208 loss_bn: 0.5975247025489807
task 6 iter 2500 loss: 15498.2724609375 tv_loss: 0.25987058877944946 norm_loss: 0.8554837107658386 task_loss: 0.003567382227629423 loss_bn: 0.6560710072517395
task 6 iter 2600 loss: 15021.271484375 tv_loss: 0.2577112317085266 norm_loss: 0.8553364276885986 task_loss: 0.0035126281436532736 loss_bn: 0.609087347984314
task 6 iter 2700 loss: 14613.6953125 tv_loss: 0.25574102997779846 norm_loss: 0.8551979660987854 task_loss: 0.0034612840972840786 loss_bn: 0.569001317024231
task 6 iter 2800 loss: 15084.1044921875 tv_loss: 0.25369593501091003 norm_loss: 0.8550499081611633 task_loss: 0.0034388727508485317 loss_bn: 0.6164348721504211
task 6 iter 2900 loss: 15491.337890625 tv_loss: 0.2519541382789612 norm_loss: 0.8549715280532837 task_loss: 0.003321954282000661 loss_bn: 0.6584231853485107
task 6 iter 3000 loss: 14600.43359375 tv_loss: 0.250275582075119 norm_loss: 0.8548835515975952 task_loss: 0.0032692402601242065 loss_bn: 0.5699647068977356
task 6 iter 3100 loss: 13955.771484375 tv_loss: 0.2489062398672104 norm_loss: 0.8548290729522705 task_loss: 0.0032327021472156048 loss_bn: 0.5059319138526917
task 6 iter 3200 loss: 14055.5185546875 tv_loss: 0.24739347398281097 norm_loss: 0.8547487258911133 task_loss: 0.0032087701838463545 loss_bn: 0.5162414908409119
task 6 iter 3300 loss: 13707.83984375 tv_loss: 0.24561917781829834 norm_loss: 0.8546127080917358 task_loss: 0.0030862120911478996 loss_bn: 0.4828529357910156
task 6 iter 3400 loss: 14965.263671875 tv_loss: 0.24395225942134857 norm_loss: 0.8545657396316528 task_loss: 0.003017194103449583 loss_bn: 0.609349250793457
task 6 iter 3500 loss: 13663.0078125 tv_loss: 0.24268710613250732 norm_loss: 0.8545142412185669 task_loss: 0.002967666834592819 loss_bn: 0.47968295216560364
task 6 iter 3600 loss: 13567.986328125 tv_loss: 0.24144265055656433 norm_loss: 0.8544619679450989 task_loss: 0.002945577958598733 loss_bn: 0.47046637535095215
task 6 iter 3700 loss: 13961.197265625 tv_loss: 0.24035492539405823 norm_loss: 0.8544138073921204 task_loss: 0.002945610322058201 loss_bn: 0.5098463296890259
task 6 iter 3800 loss: 13672.6513671875 tv_loss: 0.23920652270317078 norm_loss: 0.8543716669082642 task_loss: 0.0029035010375082493 loss_bn: 0.4814664125442505
task 6 iter 3900 loss: 13541.28125 tv_loss: 0.23842152953147888 norm_loss: 0.8543943762779236 task_loss: 0.00285243708640337 loss_bn: 0.4688251316547394
task 6 iter 4000 loss: 13810.62109375 tv_loss: 0.2374226450920105 norm_loss: 0.8543310761451721 task_loss: 0.0028611987363547087 loss_bn: 0.49574488401412964
task 6 iter 4100 loss: 14073.994140625 tv_loss: 0.236503466963768 norm_loss: 0.8542667627334595 task_loss: 0.0027448644395917654 loss_bn: 0.5233190059661865
task 6 iter 4200 loss: 14643.3203125 tv_loss: 0.23590323328971863 norm_loss: 0.8543220162391663 task_loss: 0.0026881196536123753 loss_bn: 0.5807698369026184
task 6 iter 4300 loss: 13606.57421875 tv_loss: 0.23504650592803955 norm_loss: 0.8543033599853516 task_loss: 0.0026471989694982767 loss_bn: 0.47753164172172546
task 6 iter 4400 loss: 14061.765625 tv_loss: 0.23444154858589172 norm_loss: 0.854290246963501 task_loss: 0.0026153267826884985 loss_bn: 0.5233887434005737
task 6 iter 4500 loss: 14041.7431640625 tv_loss: 0.2334931194782257 norm_loss: 0.8542280793190002 task_loss: 0.0026834357995539904 loss_bn: 0.5207768678665161
task 6 iter 4600 loss: 13002.2744140625 tv_loss: 0.2326495200395584 norm_loss: 0.8542119860649109 task_loss: 0.0025157348718494177 loss_bn: 0.41853153705596924
task 6 iter 4700 loss: 13297.130859375 tv_loss: 0.23208561539649963 norm_loss: 0.8541907072067261 task_loss: 0.00256428518332541 loss_bn: 0.44755876064300537
task 6 iter 4800 loss: 12288.07421875 tv_loss: 0.23137077689170837 norm_loss: 0.8541923761367798 task_loss: 0.002427077852189541 loss_bn: 0.34803053736686707
task 6 iter 4900 loss: 13534.76953125 tv_loss: 0.23091787099838257 norm_loss: 0.8542340993881226 task_loss: 0.0024611386470496655 loss_bn: 0.4723221957683563
task 6 iter 5000 loss: 13465.9150390625 tv_loss: 0.23027533292770386 norm_loss: 0.8541719913482666 task_loss: 0.002416068920865655 loss_bn: 0.46595606207847595
task 6 iter 5100 loss: 9783.1044921875 tv_loss: 0.23009711503982544 norm_loss: 0.854143500328064 task_loss: 0.00237678294070065 loss_bn: 0.09809815138578415
task 6 iter 5200 loss: 9742.5380859375 tv_loss: 0.2298860251903534 norm_loss: 0.8541297912597656 task_loss: 0.0023295721039175987 loss_bn: 0.0945294201374054
task 6 iter 5300 loss: 9721.6015625 tv_loss: 0.22970381379127502 norm_loss: 0.8541218042373657 task_loss: 0.0022899301256984472 loss_bn: 0.09284194558858871
task 6 iter 5400 loss: 9795.734375 tv_loss: 0.22950619459152222 norm_loss: 0.854114294052124 task_loss: 0.0022538723424077034 loss_bn: 0.10062538832426071
task 6 iter 5500 loss: 9747.0966796875 tv_loss: 0.22936642169952393 norm_loss: 0.8541228771209717 task_loss: 0.002221224829554558 loss_bn: 0.09608087688684464
task 6 iter 5600 loss: 9730.287109375 tv_loss: 0.22924485802650452 norm_loss: 0.854129433631897 task_loss: 0.0021937016863375902 loss_bn: 0.09466985613107681
task 6 iter 5700 loss: 9711.62109375 tv_loss: 0.229102224111557 norm_loss: 0.8541406989097595 task_loss: 0.002170341555029154 loss_bn: 0.09302692860364914
task 6 iter 5800 loss: 9692.765625 tv_loss: 0.22897526621818542 norm_loss: 0.8541510105133057 task_loss: 0.002150612650439143 loss_bn: 0.09132970869541168
task 6 iter 5900 loss: 9683.095703125 tv_loss: 0.2288525402545929 norm_loss: 0.8541586995124817 task_loss: 0.0021333869080990553 loss_bn: 0.09052848815917969
task 6 iter 6000 loss: 9695.5732421875 tv_loss: 0.22872355580329895 norm_loss: 0.8541630506515503 task_loss: 0.002113558119162917 loss_bn: 0.09197141230106354
task 6 iter 6100 loss: 9677.8486328125 tv_loss: 0.22860214114189148 norm_loss: 0.8541703820228577 task_loss: 0.002098297933116555 loss_bn: 0.09034537523984909
task 6 iter 6200 loss: 9667.904296875 tv_loss: 0.22848619520664215 norm_loss: 0.8541762232780457 task_loss: 0.00208225823007524 loss_bn: 0.08950678259134293
task 6 iter 6300 loss: 9669.935546875 tv_loss: 0.2283599078655243 norm_loss: 0.8541804552078247 task_loss: 0.0020667300559580326 loss_bn: 0.08986219018697739
task 6 iter 6400 loss: 9628.294921875 tv_loss: 0.22824221849441528 norm_loss: 0.8541884422302246 task_loss: 0.002050244016572833 loss_bn: 0.08585610240697861
task 6 iter 6500 loss: 9696.55078125 tv_loss: 0.22809617221355438 norm_loss: 0.8541898727416992 task_loss: 0.0020370336715132 loss_bn: 0.09281393885612488
task 6 iter 6600 loss: 9663.8330078125 tv_loss: 0.2279776930809021 norm_loss: 0.85419762134552 task_loss: 0.0020177741535007954 loss_bn: 0.08972808718681335
task 6 iter 6700 loss: 9652.5 tv_loss: 0.22786423563957214 norm_loss: 0.854202151298523 task_loss: 0.002002581488341093 loss_bn: 0.08874333649873734
task 6 iter 6800 loss: 9647.9443359375 tv_loss: 0.2277584820985794 norm_loss: 0.8542056679725647 task_loss: 0.0019884502980858088 loss_bn: 0.08842665702104568
task 6 iter 6900 loss: 9611.09765625 tv_loss: 0.22764970362186432 norm_loss: 0.8542082905769348 task_loss: 0.001974714221432805 loss_bn: 0.0848778486251831
task 6 iter 7000 loss: 9600.689453125 tv_loss: 0.22753342986106873 norm_loss: 0.8542078137397766 task_loss: 0.0019618787337094545 loss_bn: 0.08396698534488678
task 6 iter 7100 loss: 9590.3828125 tv_loss: 0.22742368280887604 norm_loss: 0.8542102575302124 task_loss: 0.0019502456998452544 loss_bn: 0.083051398396492
task 6 iter 7200 loss: 9585.234375 tv_loss: 0.227321594953537 norm_loss: 0.8542115688323975 task_loss: 0.0019387432839721441 loss_bn: 0.08265125006437302
task 6 iter 7300 loss: 9597.6201171875 tv_loss: 0.2272140085697174 norm_loss: 0.8542104959487915 task_loss: 0.0019267069874331355 loss_bn: 0.08401229977607727
task 6 iter 7400 loss: 9585.2294921875 tv_loss: 0.2271072268486023 norm_loss: 0.854211688041687 task_loss: 0.00191715476103127 loss_bn: 0.08286867290735245
task 6 iter 7500 loss: 9574.2216796875 tv_loss: 0.2270081341266632 norm_loss: 0.8542121648788452 task_loss: 0.0019083601655438542 loss_bn: 0.08185622096061707
task 6 iter 7600 loss: 9572.1435546875 tv_loss: 0.22689968347549438 norm_loss: 0.8542097806930542 task_loss: 0.0019010850228369236 loss_bn: 0.08172471076250076
task 6 iter 7700 loss: 9645.8515625 tv_loss: 0.22681069374084473 norm_loss: 0.8542143106460571 task_loss: 0.0018944545881822705 loss_bn: 0.08915811777114868
task 6 iter 7800 loss: 9616.66796875 tv_loss: 0.22671285271644592 norm_loss: 0.8542166948318481 task_loss: 0.0018825004808604717 loss_bn: 0.086357980966568
task 6 iter 7900 loss: 9593.2861328125 tv_loss: 0.22661733627319336 norm_loss: 0.8542160987854004 task_loss: 0.00187236862257123 loss_bn: 0.08412264287471771
task 6 iter 8000 loss: 9617.12890625 tv_loss: 0.2265145182609558 norm_loss: 0.8542110919952393 task_loss: 0.001862594042904675 loss_bn: 0.08661066740751266
task 6 iter 8100 loss: 9632.515625 tv_loss: 0.2264171540737152 norm_loss: 0.8542073965072632 task_loss: 0.0018533668480813503 loss_bn: 0.08824624866247177
task 6 iter 8200 loss: 9619.5224609375 tv_loss: 0.22632010281085968 norm_loss: 0.8542071580886841 task_loss: 0.0018451582873240113 loss_bn: 0.0870303362607956
task 6 iter 8300 loss: 9616.90234375 tv_loss: 0.2262279987335205 norm_loss: 0.8542048335075378 task_loss: 0.0018374366918578744 loss_bn: 0.08684878051280975
task 6 iter 8400 loss: 9609.712890625 tv_loss: 0.22612988948822021 norm_loss: 0.8542001247406006 task_loss: 0.0018317425856366754 loss_bn: 0.08619245886802673
task 6 iter 8500 loss: 9600.080078125 tv_loss: 0.22603610157966614 norm_loss: 0.8541972637176514 task_loss: 0.0018244294915348291 loss_bn: 0.08530605584383011
task 6 iter 8600 loss: 9597.83984375 tv_loss: 0.2259468138217926 norm_loss: 0.8541964292526245 task_loss: 0.001818992430344224 loss_bn: 0.08513820171356201
task 6 iter 8700 loss: 9594.7158203125 tv_loss: 0.22585612535476685 norm_loss: 0.8541942834854126 task_loss: 0.0018126053037121892 loss_bn: 0.08489276468753815
task 6 iter 8800 loss: 9593.3701171875 tv_loss: 0.22577708959579468 norm_loss: 0.8541921973228455 task_loss: 0.0018056657863780856 loss_bn: 0.08483034372329712
task 6 iter 8900 loss: 9565.8330078125 tv_loss: 0.22568461298942566 norm_loss: 0.8541857004165649 task_loss: 0.0017974124057218432 loss_bn: 0.0821666419506073
task 6 iter 9000 loss: 9635.294921875 tv_loss: 0.22556278109550476 norm_loss: 0.8541774749755859 task_loss: 0.0017947497544810176 loss_bn: 0.08914894610643387
task 6 iter 9100 loss: 9572.1796875 tv_loss: 0.22546261548995972 norm_loss: 0.8541760444641113 task_loss: 0.0017853293102234602 loss_bn: 0.08293402940034866
task 6 iter 9200 loss: 9591.2763671875 tv_loss: 0.22535383701324463 norm_loss: 0.8541669845581055 task_loss: 0.0017806374235078692 loss_bn: 0.08490072190761566
task 6 iter 9300 loss: 9566.1943359375 tv_loss: 0.22525645792484283 norm_loss: 0.8541626930236816 task_loss: 0.0017746269004419446 loss_bn: 0.08245788514614105
task 6 iter 9400 loss: 9559.8154296875 tv_loss: 0.2251691222190857 norm_loss: 0.85416179895401 task_loss: 0.0017654488328844309 loss_bn: 0.08191357553005219
task 6 iter 9500 loss: 9529.5439453125 tv_loss: 0.225086510181427 norm_loss: 0.8541594743728638 task_loss: 0.001757244230248034 loss_bn: 0.07897158712148666
task 6 iter 9600 loss: 9543.6865234375 tv_loss: 0.22500604391098022 norm_loss: 0.8541560173034668 task_loss: 0.001751010655425489 loss_bn: 0.08045239746570587
task 6 iter 9700 loss: 9572.767578125 tv_loss: 0.22491496801376343 norm_loss: 0.8541544675827026 task_loss: 0.001739527564495802 loss_bn: 0.08347778022289276
task 6 iter 9800 loss: 9548.6083984375 tv_loss: 0.22482135891914368 norm_loss: 0.8541504740715027 task_loss: 0.0017330272821709514 loss_bn: 0.08113180100917816
task 6 iter 9900 loss: 9550.2626953125 tv_loss: 0.22473445534706116 norm_loss: 0.85414719581604 task_loss: 0.0017253403784707189 loss_bn: 0.08137834072113037
task 6 iter 10000 loss: 9547.279296875 tv_loss: 0.22467155754566193 norm_loss: 0.854145884513855 task_loss: 0.0017192388186231256 loss_bn: 0.08114293962717056
task 7 iter 100 loss: 102725.0703125 tv_loss: 0.46935784816741943 norm_loss: 0.9372623562812805 task_loss: 0.025890229269862175 loss_bn: 9.071648597717285
task 7 iter 200 loss: 56105.953125 tv_loss: 0.4137035012245178 norm_loss: 0.9010145664215088 task_loss: 0.015860922634601593 loss_bn: 4.546834468841553
task 7 iter 300 loss: 41091.5859375 tv_loss: 0.38755369186401367 norm_loss: 0.8802382349967957 task_loss: 0.01280346978455782 loss_bn: 3.0970101356506348
task 7 iter 400 loss: 34007.55078125 tv_loss: 0.37073951959609985 norm_loss: 0.8706719875335693 task_loss: 0.01078812312334776 loss_bn: 2.418494462966919
task 7 iter 500 loss: 29590.986328125 tv_loss: 0.35842546820640564 norm_loss: 0.8659600615501404 task_loss: 0.009350216016173363 loss_bn: 1.9960521459579468
task 7 iter 600 loss: 26918.2265625 tv_loss: 0.34856128692626953 norm_loss: 0.8634092211723328 task_loss: 0.008445226587355137 loss_bn: 1.7404756546020508
task 7 iter 700 loss: 24929.587890625 tv_loss: 0.34018516540527344 norm_loss: 0.8618189692497253 task_loss: 0.0076620010659098625 loss_bn: 1.551118016242981
task 7 iter 800 loss: 23210.501953125 tv_loss: 0.33274737000465393 norm_loss: 0.8607381582260132 task_loss: 0.007136052008718252 loss_bn: 1.3856240510940552
task 7 iter 900 loss: 21745.62109375 tv_loss: 0.3258940875530243 norm_loss: 0.8599637746810913 task_loss: 0.006688221357762814 loss_bn: 1.2444572448730469
task 7 iter 1000 loss: 20522.333984375 tv_loss: 0.319665789604187 norm_loss: 0.8593403100967407 task_loss: 0.006312721874564886 loss_bn: 1.126569151878357
task 7 iter 1100 loss: 20636.515625 tv_loss: 0.31378814578056335 norm_loss: 0.8588343858718872 task_loss: 0.006092379800975323 loss_bn: 1.1407554149627686
task 7 iter 1200 loss: 18622.40234375 tv_loss: 0.30777278542518616 norm_loss: 0.8583192825317383 task_loss: 0.005695678293704987 loss_bn: 0.9438866376876831
task 7 iter 1300 loss: 17752.97265625 tv_loss: 0.3025085926055908 norm_loss: 0.8579236268997192 task_loss: 0.005414578132331371 loss_bn: 0.8602028489112854
task 7 iter 1400 loss: 16869.021484375 tv_loss: 0.2977668046951294 norm_loss: 0.8575971126556396 task_loss: 0.005243106745183468 loss_bn: 0.7738963961601257
task 7 iter 1500 loss: 16960.373046875 tv_loss: 0.293315589427948 norm_loss: 0.857296884059906 task_loss: 0.005033829715102911 loss_bn: 0.7854688763618469
task 7 iter 1600 loss: 16183.4609375 tv_loss: 0.2888713479042053 norm_loss: 0.8569921851158142 task_loss: 0.0047526052221655846 loss_bn: 0.7109391689300537
task 7 iter 1700 loss: 15667.1298828125 tv_loss: 0.2849035859107971 norm_loss: 0.8567769527435303 task_loss: 0.0046001276932656765 loss_bn: 0.6610857248306274
task 7 iter 1800 loss: 14977.2734375 tv_loss: 0.2810465693473816 norm_loss: 0.8565735816955566 task_loss: 0.004414374008774757 loss_bn: 0.5941995978355408
task 7 iter 1900 loss: 16962.212890625 tv_loss: 0.2777037024497986 norm_loss: 0.8564500212669373 task_loss: 0.00429964903742075 loss_bn: 0.7939978241920471
task 7 iter 2000 loss: 16416.076171875 tv_loss: 0.27455490827560425 norm_loss: 0.856221079826355 task_loss: 0.004272119142115116 loss_bn: 0.7399198412895203
task 7 iter 2100 loss: 16226.203125 tv_loss: 0.27190664410591125 norm_loss: 0.8560851216316223 task_loss: 0.0041207848116755486 loss_bn: 0.722608208656311
task 7 iter 2200 loss: 15870.37890625 tv_loss: 0.2695730924606323 norm_loss: 0.8559837341308594 task_loss: 0.004039088264107704 loss_bn: 0.6879675388336182
task 7 iter 2300 loss: 16640.048828125 tv_loss: 0.26694929599761963 norm_loss: 0.8557780981063843 task_loss: 0.004054327495396137 loss_bn: 0.7650139927864075
task 7 iter 2400 loss: 15556.9541015625 tv_loss: 0.264548122882843 norm_loss: 0.8556176424026489 task_loss: 0.003892810083925724 loss_bn: 0.6585041880607605
task 7 iter 2500 loss: 15648.330078125 tv_loss: 0.2624850273132324 norm_loss: 0.8555635213851929 task_loss: 0.003790012327954173 loss_bn: 0.6687445640563965
task 7 iter 2600 loss: 15325.0703125 tv_loss: 0.2602582573890686 norm_loss: 0.855350911617279 task_loss: 0.003738672472536564 loss_bn: 0.6371667385101318
task 7 iter 2700 loss: 14756.931640625 tv_loss: 0.2581745386123657 norm_loss: 0.8551982045173645 task_loss: 0.0037079621106386185 loss_bn: 0.5808336138725281
task 7 iter 2800 loss: 16240.32421875 tv_loss: 0.2561507821083069 norm_loss: 0.8550528287887573 task_loss: 0.003692008089274168 loss_bn: 0.7294980883598328
task 7 iter 2900 loss: 14826.259765625 tv_loss: 0.2543165683746338 norm_loss: 0.8549287915229797 task_loss: 0.003596849739551544 loss_bn: 0.5891855955123901
task 7 iter 3000 loss: 12851.9072265625 tv_loss: 0.252064049243927 norm_loss: 0.8547945618629456 task_loss: 0.0033699332270771265 loss_bn: 0.39417627453804016
task 7 iter 3100 loss: 12786.455078125 tv_loss: 0.24998819828033447 norm_loss: 0.8546909093856812 task_loss: 0.0032599526457488537 loss_bn: 0.38885512948036194
task 7 iter 3200 loss: 12356.1572265625 tv_loss: 0.24820640683174133 norm_loss: 0.8546085357666016 task_loss: 0.003214671043679118 loss_bn: 0.3463783860206604
task 7 iter 3300 loss: 12381.1298828125 tv_loss: 0.2466946840286255 norm_loss: 0.8545373678207397 task_loss: 0.003140573389828205 loss_bn: 0.34970295429229736
task 7 iter 3400 loss: 12256.951171875 tv_loss: 0.24509137868881226 norm_loss: 0.8544557094573975 task_loss: 0.003071228275075555 loss_bn: 0.33807626366615295
task 7 iter 3500 loss: 12688.76953125 tv_loss: 0.2435193657875061 norm_loss: 0.8543710112571716 task_loss: 0.0030161598697304726 loss_bn: 0.3819091320037842
task 7 iter 3600 loss: 12101.3369140625 tv_loss: 0.24200734496116638 norm_loss: 0.8543192744255066 task_loss: 0.002942271763458848 loss_bn: 0.3239716589450836
task 7 iter 3700 loss: 12275.9345703125 tv_loss: 0.2406427264213562 norm_loss: 0.8542647361755371 task_loss: 0.002913982607424259 loss_bn: 0.3417823910713196
task 7 iter 3800 loss: 12190.9736328125 tv_loss: 0.23931783437728882 norm_loss: 0.8542088270187378 task_loss: 0.0028223549015820026 loss_bn: 0.3342718482017517
task 7 iter 3900 loss: 12289.8447265625 tv_loss: 0.23804312944412231 norm_loss: 0.8541653156280518 task_loss: 0.002762135351076722 loss_bn: 0.3448173999786377
task 7 iter 4000 loss: 12267.794921875 tv_loss: 0.23691999912261963 norm_loss: 0.8541452288627625 task_loss: 0.0027083544991910458 loss_bn: 0.3431814908981323
task 7 iter 4100 loss: 12486.421875 tv_loss: 0.2358458936214447 norm_loss: 0.8541252613067627 task_loss: 0.0026839899364858866 loss_bn: 0.36531856656074524
task 7 iter 4200 loss: 11686.2666015625 tv_loss: 0.23497551679611206 norm_loss: 0.8541327714920044 task_loss: 0.002594882855191827 loss_bn: 0.28619521856307983
task 7 iter 4300 loss: 11531.283203125 tv_loss: 0.2340872883796692 norm_loss: 0.8541287779808044 task_loss: 0.0025645464193075895 loss_bn: 0.2710132300853729
task 7 iter 4400 loss: 11493.29296875 tv_loss: 0.23322442173957825 norm_loss: 0.8541475534439087 task_loss: 0.002481848234310746 loss_bn: 0.2680310606956482
task 7 iter 4500 loss: 11483.1357421875 tv_loss: 0.23245373368263245 norm_loss: 0.8541494011878967 task_loss: 0.0024291640147566795 loss_bn: 0.26754796504974365
task 7 iter 4600 loss: 11632.474609375 tv_loss: 0.23167097568511963 norm_loss: 0.8541210293769836 task_loss: 0.002400915138423443 loss_bn: 0.2828005850315094
task 7 iter 4700 loss: 11430.5498046875 tv_loss: 0.23102343082427979 norm_loss: 0.8541204333305359 task_loss: 0.0023450476583093405 loss_bn: 0.26317381858825684
task 7 iter 4800 loss: 11875.34375 tv_loss: 0.23031821846961975 norm_loss: 0.8541044592857361 task_loss: 0.002299892483279109 loss_bn: 0.3081277906894684
task 7 iter 4900 loss: 11559.015625 tv_loss: 0.22955650091171265 norm_loss: 0.8540340065956116 task_loss: 0.0022830404341220856 loss_bn: 0.27674156427383423
task 7 iter 5000 loss: 11338.638671875 tv_loss: 0.22906172275543213 norm_loss: 0.854026734828949 task_loss: 0.002235283376649022 loss_bn: 0.25519371032714844
task 7 iter 5100 loss: 9729.8193359375 tv_loss: 0.2287634164094925 norm_loss: 0.8539743423461914 task_loss: 0.0022108128760010004 loss_bn: 0.09461186081171036
task 7 iter 5200 loss: 9694.935546875 tv_loss: 0.2286372184753418 norm_loss: 0.8539732694625854 task_loss: 0.002175327157601714 loss_bn: 0.09148066490888596
task 7 iter 5300 loss: 9673.79296875 tv_loss: 0.22851741313934326 norm_loss: 0.8539764881134033 task_loss: 0.002149752341210842 loss_bn: 0.08962009102106094
task 7 iter 5400 loss: 9649.9521484375 tv_loss: 0.22840526700019836 norm_loss: 0.8539827466011047 task_loss: 0.0021276352927088737 loss_bn: 0.08745206147432327
task 7 iter 5500 loss: 9637.07421875 tv_loss: 0.22830048203468323 norm_loss: 0.8539879322052002 task_loss: 0.0021100365556776524 loss_bn: 0.0863361582159996
task 7 iter 5600 loss: 9689.638671875 tv_loss: 0.2281629592180252 norm_loss: 0.8539771437644958 task_loss: 0.0020940229296684265 loss_bn: 0.09176485240459442
task 7 iter 5700 loss: 9656.1708984375 tv_loss: 0.22806024551391602 norm_loss: 0.8539880514144897 task_loss: 0.00207589752972126 loss_bn: 0.08858942985534668
task 7 iter 5800 loss: 9672.8623046875 tv_loss: 0.2279798537492752 norm_loss: 0.8539893627166748 task_loss: 0.002057302976027131 loss_bn: 0.09044405817985535
task 7 iter 5900 loss: 9654.7109375 tv_loss: 0.22787678241729736 norm_loss: 0.8539915680885315 task_loss: 0.002042849315330386 loss_bn: 0.0887722298502922
task 7 iter 6000 loss: 9651.5009765625 tv_loss: 0.22778022289276123 norm_loss: 0.853992223739624 task_loss: 0.002032072748988867 loss_bn: 0.08855941146612167
task 7 iter 6100 loss: 9695.96875 tv_loss: 0.2276807576417923 norm_loss: 0.8539937138557434 task_loss: 0.0020225781481713057 loss_bn: 0.09310053288936615
task 7 iter 6200 loss: 9640.220703125 tv_loss: 0.22757118940353394 norm_loss: 0.853998064994812 task_loss: 0.002002703258767724 loss_bn: 0.08772127330303192
task 7 iter 6300 loss: 9609.3603515625 tv_loss: 0.22746309638023376 norm_loss: 0.8539960384368896 task_loss: 0.0019868104718625546 loss_bn: 0.08479728549718857
task 7 iter 6400 loss: 9616.0625 tv_loss: 0.22735488414764404 norm_loss: 0.853992223739624 task_loss: 0.001973543083295226 loss_bn: 0.08560507744550705
task 7 iter 6500 loss: 9630.658203125 tv_loss: 0.2272607386112213 norm_loss: 0.8539972305297852 task_loss: 0.00195930153131485 loss_bn: 0.08720290660858154
task 7 iter 6600 loss: 9609.837890625 tv_loss: 0.2271500825881958 norm_loss: 0.8539924621582031 task_loss: 0.0019500008784234524 loss_bn: 0.08521981537342072
task 7 iter 6700 loss: 9609.3955078125 tv_loss: 0.22704707086086273 norm_loss: 0.8539891242980957 task_loss: 0.0019407860236242414 loss_bn: 0.08527206629514694
task 7 iter 6800 loss: 9591.287109375 tv_loss: 0.22695405781269073 norm_loss: 0.853987991809845 task_loss: 0.0019335871329531074 loss_bn: 0.08353536576032639
task 7 iter 6900 loss: 9585.5126953125 tv_loss: 0.22686420381069183 norm_loss: 0.8539854288101196 task_loss: 0.001925613614730537 loss_bn: 0.0830409973859787
task 7 iter 7000 loss: 9578.935546875 tv_loss: 0.2267799824476242 norm_loss: 0.8539835214614868 task_loss: 0.00191854580771178 loss_bn: 0.08245685696601868
task 7 iter 7100 loss: 9566.7470703125 tv_loss: 0.22669775784015656 norm_loss: 0.8539813160896301 task_loss: 0.0019119000062346458 loss_bn: 0.08130746334791183
task 7 iter 7200 loss: 9566.8525390625 tv_loss: 0.22662627696990967 norm_loss: 0.8539799451828003 task_loss: 0.0019030433613806963 loss_bn: 0.08140859007835388
task 7 iter 7300 loss: 9582.4228515625 tv_loss: 0.22655446827411652 norm_loss: 0.8539775609970093 task_loss: 0.001896075438708067 loss_bn: 0.08303845673799515
task 7 iter 7400 loss: 9567.337890625 tv_loss: 0.22646787762641907 norm_loss: 0.8539748191833496 task_loss: 0.0018890018109232187 loss_bn: 0.08160434663295746
task 7 iter 7500 loss: 9553.2216796875 tv_loss: 0.22638559341430664 norm_loss: 0.8539713621139526 task_loss: 0.0018828640459105372 loss_bn: 0.08025828748941422
task 7 iter 7600 loss: 9571.69921875 tv_loss: 0.22629863023757935 norm_loss: 0.8539667725563049 task_loss: 0.0018773585325106978 loss_bn: 0.08216658234596252
task 7 iter 7700 loss: 9559.9326171875 tv_loss: 0.2262115776538849 norm_loss: 0.8539618253707886 task_loss: 0.0018707322888076305 loss_bn: 0.08106202632188797
task 7 iter 7800 loss: 9548.69921875 tv_loss: 0.2261306196451187 norm_loss: 0.853958249092102 task_loss: 0.0018644847441464663 loss_bn: 0.08000553399324417
task 7 iter 7900 loss: 9538.16796875 tv_loss: 0.2260548174381256 norm_loss: 0.8539578914642334 task_loss: 0.001858317176811397 loss_bn: 0.07901514321565628
task 7 iter 8000 loss: 9531.8310546875 tv_loss: 0.22597700357437134 norm_loss: 0.8539566993713379 task_loss: 0.0018553787376731634 loss_bn: 0.07841280847787857
task 7 iter 8100 loss: 9644.294921875 tv_loss: 0.22586855292320251 norm_loss: 0.8539414405822754 task_loss: 0.0018492526141926646 loss_bn: 0.08973687142133713
task 7 iter 8200 loss: 9597.4091796875 tv_loss: 0.22579067945480347 norm_loss: 0.8539396524429321 task_loss: 0.0018395218066871166 loss_bn: 0.08514812588691711
task 7 iter 8300 loss: 9571.6923828125 tv_loss: 0.22571244835853577 norm_loss: 0.8539362549781799 task_loss: 0.0018324409611523151 loss_bn: 0.08265142887830734
task 7 iter 8400 loss: 9557.3671875 tv_loss: 0.22563444077968597 norm_loss: 0.8539321422576904 task_loss: 0.0018270417349413037 loss_bn: 0.08127786964178085
task 7 iter 8500 loss: 9556.955078125 tv_loss: 0.22555886209011078 norm_loss: 0.853927493095398 task_loss: 0.0018208518158644438 loss_bn: 0.08130393177270889
task 7 iter 8600 loss: 9531.416015625 tv_loss: 0.22547724843025208 norm_loss: 0.853922426700592 task_loss: 0.0018164609791710973 loss_bn: 0.07879985123872757
task 7 iter 8700 loss: 9515.5498046875 tv_loss: 0.22540095448493958 norm_loss: 0.8539168834686279 task_loss: 0.0018092397367581725 loss_bn: 0.07729172706604004
task 7 iter 8800 loss: 9670.556640625 tv_loss: 0.22534409165382385 norm_loss: 0.8539115190505981 task_loss: 0.0018049462232738733 loss_bn: 0.09284117817878723
task 7 iter 8900 loss: 9597.4560546875 tv_loss: 0.22527030110359192 norm_loss: 0.8539140224456787 task_loss: 0.0017982050776481628 loss_bn: 0.08559674769639969
task 7 iter 9000 loss: 9579.5517578125 tv_loss: 0.22519215941429138 norm_loss: 0.8539102077484131 task_loss: 0.0017925145803019404 loss_bn: 0.0838678628206253
task 7 iter 9100 loss: 9570.9111328125 tv_loss: 0.22512005269527435 norm_loss: 0.8539053797721863 task_loss: 0.0017867627320811152 loss_bn: 0.08306688070297241
task 7 iter 9200 loss: 9574.5595703125 tv_loss: 0.22504383325576782 norm_loss: 0.8538991808891296 task_loss: 0.0017833657329902053 loss_bn: 0.08347263932228088
task 7 iter 9300 loss: 9575.759765625 tv_loss: 0.22496569156646729 norm_loss: 0.853894829750061 task_loss: 0.0017790093552321196 loss_bn: 0.0836414098739624
task 7 iter 9400 loss: 9554.4921875 tv_loss: 0.22489312291145325 norm_loss: 0.8538905382156372 task_loss: 0.0017759875627234578 loss_bn: 0.08154985308647156
task 7 iter 9500 loss: 9539.8935546875 tv_loss: 0.22481389343738556 norm_loss: 0.8538835644721985 task_loss: 0.001770566450431943 loss_bn: 0.08015193045139313
task 7 iter 9600 loss: 9611.228515625 tv_loss: 0.2247287929058075 norm_loss: 0.8538695573806763 task_loss: 0.0017653764225542545 loss_bn: 0.08735227584838867
task 7 iter 9700 loss: 9591.1103515625 tv_loss: 0.22465550899505615 norm_loss: 0.8538680076599121 task_loss: 0.001759561593644321 loss_bn: 0.08540085703134537
task 7 iter 9800 loss: 9578.064453125 tv_loss: 0.2245841920375824 norm_loss: 0.8538641333580017 task_loss: 0.0017539486289024353 loss_bn: 0.08415691554546356
task 7 iter 9900 loss: 9563.5439453125 tv_loss: 0.22451189160346985 norm_loss: 0.8538594245910645 task_loss: 0.0017497484805062413 loss_bn: 0.08275238424539566
task 7 iter 10000 loss: 9556.0224609375 tv_loss: 0.22444576025009155 norm_loss: 0.8538551926612854 task_loss: 0.0017458826769143343 loss_bn: 0.08204378932714462
task 8 iter 100 loss: 96360.3828125 tv_loss: 0.46203720569610596 norm_loss: 0.9348629117012024 task_loss: 0.022308655083179474 loss_bn: 8.473468780517578
task 8 iter 200 loss: 53741.609375 tv_loss: 0.4085671901702881 norm_loss: 0.8974930047988892 task_loss: 0.013974800705909729 loss_bn: 4.332834243774414
task 8 iter 300 loss: 39887.875 tv_loss: 0.38403066992759705 norm_loss: 0.8778667449951172 task_loss: 0.01130722276866436 loss_bn: 2.9940083026885986
task 8 iter 400 loss: 33069.01171875 tv_loss: 0.3681901693344116 norm_loss: 0.8691449761390686 task_loss: 0.009401347488164902 loss_bn: 2.3400607109069824
task 8 iter 500 loss: 28974.650390625 tv_loss: 0.35650092363357544 norm_loss: 0.8649094104766846 task_loss: 0.008331095799803734 loss_bn: 1.945679783821106
task 8 iter 600 loss: 26271.955078125 tv_loss: 0.34701618552207947 norm_loss: 0.862606406211853 task_loss: 0.007476772181689739 loss_bn: 1.6863511800765991
task 8 iter 700 loss: 24365.70703125 tv_loss: 0.33873897790908813 norm_loss: 0.8612194061279297 task_loss: 0.006916378159075975 loss_bn: 1.5028001070022583
task 8 iter 800 loss: 22657.953125 tv_loss: 0.33130043745040894 norm_loss: 0.8602812886238098 task_loss: 0.006354556418955326 loss_bn: 1.3386555910110474
task 8 iter 900 loss: 21275.5078125 tv_loss: 0.3244813084602356 norm_loss: 0.8596078157424927 task_loss: 0.006048803683370352 loss_bn: 1.2042102813720703
task 8 iter 1000 loss: 20514.029296875 tv_loss: 0.3182549774646759 norm_loss: 0.8591016530990601 task_loss: 0.005636894144117832 loss_bn: 1.1327497959136963
task 8 iter 1100 loss: 19265.08203125 tv_loss: 0.3124491274356842 norm_loss: 0.8586876392364502 task_loss: 0.005374743603169918 loss_bn: 1.010948657989502
task 8 iter 1200 loss: 18999.861328125 tv_loss: 0.3069677948951721 norm_loss: 0.8582848906517029 task_loss: 0.005180380307137966 loss_bn: 0.9868277907371521
task 8 iter 1300 loss: 19972.1640625 tv_loss: 0.3015597462654114 norm_loss: 0.8579375147819519 task_loss: 0.004898421932011843 loss_bn: 1.087278962135315
task 8 iter 1400 loss: 18803.466796875 tv_loss: 0.2968873381614685 norm_loss: 0.8575932383537292 task_loss: 0.004751983098685741 loss_bn: 0.9722647666931152
task 8 iter 1500 loss: 18031.390625 tv_loss: 0.29247328639030457 norm_loss: 0.8572837114334106 task_loss: 0.004511562641710043 loss_bn: 0.897814929485321
task 8 iter 1600 loss: 18362.3671875 tv_loss: 0.2885669469833374 norm_loss: 0.857064962387085 task_loss: 0.004407308995723724 loss_bn: 0.9322131276130676
task 8 iter 1700 loss: 18185.84765625 tv_loss: 0.28449082374572754 norm_loss: 0.8567678928375244 task_loss: 0.004298599902540445 loss_bn: 0.9159860610961914
task 8 iter 1800 loss: 17268.30859375 tv_loss: 0.28100213408470154 norm_loss: 0.8566017150878906 task_loss: 0.004080019425600767 loss_bn: 0.8266189694404602
task 8 iter 1900 loss: 16552.74609375 tv_loss: 0.2779778838157654 norm_loss: 0.8564134836196899 task_loss: 0.0039300029166042805 loss_bn: 0.7567813396453857
task 8 iter 2000 loss: 17201.97265625 tv_loss: 0.27439844608306885 norm_loss: 0.8561596274375916 task_loss: 0.003815676784142852 loss_bn: 0.8231368660926819
task 8 iter 2100 loss: 16204.802734375 tv_loss: 0.2715456783771515 norm_loss: 0.856026291847229 task_loss: 0.0037440587766468525 loss_bn: 0.7242979407310486
task 8 iter 2200 loss: 15795.806640625 tv_loss: 0.2687417268753052 norm_loss: 0.8558527231216431 task_loss: 0.003754852106794715 loss_bn: 0.6834919452667236
task 8 iter 2300 loss: 16401.13671875 tv_loss: 0.26618340611457825 norm_loss: 0.8557214736938477 task_loss: 0.0036822345573455095 loss_bn: 0.7449080944061279
task 8 iter 2400 loss: 14873.763671875 tv_loss: 0.26356545090675354 norm_loss: 0.8555260896682739 task_loss: 0.003374346299096942 loss_bn: 0.5954712629318237
task 8 iter 2500 loss: 16021.5107421875 tv_loss: 0.2609158754348755 norm_loss: 0.8554337024688721 task_loss: 0.0033360302913933992 loss_bn: 0.7107479572296143
task 8 iter 2600 loss: 15151.0546875 tv_loss: 0.2589499056339264 norm_loss: 0.8553286790847778 task_loss: 0.003304526675492525 loss_bn: 0.624142050743103
task 8 iter 2700 loss: 14971.138671875 tv_loss: 0.2565258741378784 norm_loss: 0.8550733327865601 task_loss: 0.003302728058770299 loss_bn: 0.6064479351043701
task 8 iter 2800 loss: 14638.21484375 tv_loss: 0.2547038197517395 norm_loss: 0.8550295233726501 task_loss: 0.0031913770362734795 loss_bn: 0.5743312239646912
task 8 iter 2900 loss: 12469.716796875 tv_loss: 0.2522469460964203 norm_loss: 0.8548278212547302 task_loss: 0.0031176472548395395 loss_bn: 0.3584448993206024
task 8 iter 3000 loss: 14752.24609375 tv_loss: 0.2505660057067871 norm_loss: 0.8547951579093933 task_loss: 0.0030975574627518654 loss_bn: 0.5869482159614563
task 8 iter 3100 loss: 14472.19921875 tv_loss: 0.24901050329208374 norm_loss: 0.8547201156616211 task_loss: 0.003047338919714093 loss_bn: 0.5595363974571228
task 8 iter 3200 loss: 14850.8388671875 tv_loss: 0.2475282847881317 norm_loss: 0.8545993566513062 task_loss: 0.0029301121830940247 loss_bn: 0.5987082123756409
task 8 iter 3300 loss: 14265.908203125 tv_loss: 0.2463628053665161 norm_loss: 0.8545780181884766 task_loss: 0.0029216264374554157 loss_bn: 0.5403329133987427
task 8 iter 3400 loss: 14026.263671875 tv_loss: 0.2445279210805893 norm_loss: 0.8544220924377441 task_loss: 0.0028804100584238768 loss_bn: 0.5169548988342285
task 8 iter 3500 loss: 13896.6953125 tv_loss: 0.24358347058296204 norm_loss: 0.8544661402702332 task_loss: 0.0028299603145569563 loss_bn: 0.5044679045677185
task 8 iter 3600 loss: 15948.052734375 tv_loss: 0.2418898642063141 norm_loss: 0.8543286323547363 task_loss: 0.002892422489821911 loss_bn: 0.7091334462165833
task 8 iter 3700 loss: 13530.1650390625 tv_loss: 0.2408369779586792 norm_loss: 0.8543186187744141 task_loss: 0.002750001149252057 loss_bn: 0.4687894582748413
task 8 iter 3800 loss: 14425.525390625 tv_loss: 0.2397424429655075 norm_loss: 0.8542557954788208 task_loss: 0.0027525085024535656 loss_bn: 0.5583742260932922
task 8 iter 3900 loss: 14194.025390625 tv_loss: 0.23866453766822815 norm_loss: 0.8542051315307617 task_loss: 0.0026964619755744934 loss_bn: 0.5358461141586304
task 8 iter 4000 loss: 13825.3828125 tv_loss: 0.23766538500785828 norm_loss: 0.8541924357414246 task_loss: 0.0026399933267384768 loss_bn: 0.49956923723220825
task 8 iter 4100 loss: 13500.1142578125 tv_loss: 0.23698411881923676 norm_loss: 0.8542167544364929 task_loss: 0.0026362568605691195 loss_bn: 0.46706220507621765
task 8 iter 4200 loss: 13361.9453125 tv_loss: 0.236347496509552 norm_loss: 0.8542380332946777 task_loss: 0.00256608659401536 loss_bn: 0.4539322257041931
task 8 iter 4300 loss: 13003.310546875 tv_loss: 0.23551657795906067 norm_loss: 0.8542274236679077 task_loss: 0.002543298527598381 loss_bn: 0.41831544041633606
task 8 iter 4400 loss: 13327.1982421875 tv_loss: 0.23464497923851013 norm_loss: 0.8542245626449585 task_loss: 0.002511112717911601 loss_bn: 0.45103761553764343
task 8 iter 4500 loss: 13340.88671875 tv_loss: 0.23392002284526825 norm_loss: 0.8541533946990967 task_loss: 0.0024684893433004618 loss_bn: 0.4529111683368683
task 8 iter 4600 loss: 12971.3583984375 tv_loss: 0.2332693189382553 norm_loss: 0.8541620373725891 task_loss: 0.0024275844916701317 loss_bn: 0.4163653552532196
task 8 iter 4700 loss: 13201.947265625 tv_loss: 0.2323644459247589 norm_loss: 0.8541316390037537 task_loss: 0.0023809417616575956 loss_bn: 0.43992993235588074
task 8 iter 4800 loss: 14287.228515625 tv_loss: 0.23173460364341736 norm_loss: 0.8541028499603271 task_loss: 0.002391023328527808 loss_bn: 0.5483925342559814
task 8 iter 4900 loss: 13574.51953125 tv_loss: 0.2311391681432724 norm_loss: 0.8540664911270142 task_loss: 0.0023849080316722393 loss_bn: 0.47722500562667847
task 8 iter 5000 loss: 14193.927734375 tv_loss: 0.2305368334054947 norm_loss: 0.8539935946464539 task_loss: 0.0022772045340389013 loss_bn: 0.5403217077255249
task 8 iter 5100 loss: 9804.61328125 tv_loss: 0.23042741417884827 norm_loss: 0.8540256023406982 task_loss: 0.0022450480610132217 loss_bn: 0.10168100148439407
task 8 iter 5200 loss: 9837.353515625 tv_loss: 0.23022693395614624 norm_loss: 0.8540076613426208 task_loss: 0.002197155961766839 loss_bn: 0.10545385628938675
task 8 iter 5300 loss: 9772.7080078125 tv_loss: 0.23005113005638123 norm_loss: 0.8540058135986328 task_loss: 0.0021602034103125334 loss_bn: 0.09936239570379257
task 8 iter 5400 loss: 9747.5517578125 tv_loss: 0.22990089654922485 norm_loss: 0.8540098667144775 task_loss: 0.0021312839817255735 loss_bn: 0.09713346511125565
task 8 iter 5500 loss: 9730.568359375 tv_loss: 0.22976534068584442 norm_loss: 0.8540186882019043 task_loss: 0.002106450730934739 loss_bn: 0.09567593038082123
task 8 iter 5600 loss: 9715.953125 tv_loss: 0.22963878512382507 norm_loss: 0.8540290594100952 task_loss: 0.0020851651206612587 loss_bn: 0.09441814571619034
task 8 iter 5700 loss: 9701.3984375 tv_loss: 0.2295188009738922 norm_loss: 0.8540396690368652 task_loss: 0.0020664860494434834 loss_bn: 0.09314018487930298
task 8 iter 5800 loss: 9696.35546875 tv_loss: 0.2294001430273056 norm_loss: 0.8540509343147278 task_loss: 0.0020482568070292473 loss_bn: 0.09280805289745331
task 8 iter 5900 loss: 9703.3330078125 tv_loss: 0.22927060723304749 norm_loss: 0.8540568351745605 task_loss: 0.00202711159363389 loss_bn: 0.09371260553598404
task 8 iter 6000 loss: 9693.9287109375 tv_loss: 0.2291484773159027 norm_loss: 0.8540657758712769 task_loss: 0.0020035174675285816 loss_bn: 0.09300034493207932
task 8 iter 6100 loss: 9675.91015625 tv_loss: 0.22902733087539673 norm_loss: 0.8540747165679932 task_loss: 0.0019865373615175486 loss_bn: 0.09136064350605011
task 8 iter 6200 loss: 9665.6533203125 tv_loss: 0.22891384363174438 norm_loss: 0.8540810942649841 task_loss: 0.0019697544630616903 loss_bn: 0.09049753844738007
task 8 iter 6300 loss: 9659.87109375 tv_loss: 0.22880271077156067 norm_loss: 0.8540856838226318 task_loss: 0.0019572866149246693 loss_bn: 0.09004053473472595
task 8 iter 6400 loss: 9637.2802734375 tv_loss: 0.22869160771369934 norm_loss: 0.8540904521942139 task_loss: 0.0019434739369899035 loss_bn: 0.08791588246822357
task 8 iter 6500 loss: 9653.705078125 tv_loss: 0.22855620086193085 norm_loss: 0.8540874719619751 task_loss: 0.0019252237398177385 loss_bn: 0.08974520117044449
task 8 iter 6600 loss: 9642.3046875 tv_loss: 0.228424072265625 norm_loss: 0.8540911674499512 task_loss: 0.001907592872157693 loss_bn: 0.08877912908792496
task 8 iter 6700 loss: 9623.8212890625 tv_loss: 0.22831027209758759 norm_loss: 0.8540964126586914 task_loss: 0.001893844222649932 loss_bn: 0.08706417679786682
task 8 iter 6800 loss: 9663.4814453125 tv_loss: 0.22819818556308746 norm_loss: 0.8540988564491272 task_loss: 0.0018838192336261272 loss_bn: 0.09112906455993652
task 8 iter 6900 loss: 9637.482421875 tv_loss: 0.22809359431266785 norm_loss: 0.8541051149368286 task_loss: 0.0018675189930945635 loss_bn: 0.08868706226348877
task 8 iter 7000 loss: 9624.9013671875 tv_loss: 0.22798775136470795 norm_loss: 0.8541091680526733 task_loss: 0.0018537476425990462 loss_bn: 0.08756360411643982
task 8 iter 7100 loss: 9594.1806640625 tv_loss: 0.22788873314857483 norm_loss: 0.8541107177734375 task_loss: 0.001837757881730795 loss_bn: 0.08465086668729782
task 8 iter 7200 loss: 9702.57421875 tv_loss: 0.22779786586761475 norm_loss: 0.8541136980056763 task_loss: 0.0018222823273390532 loss_bn: 0.09564293175935745
task 8 iter 7300 loss: 9632.48828125 tv_loss: 0.2276896834373474 norm_loss: 0.854116678237915 task_loss: 0.0018076588166877627 loss_bn: 0.08877865970134735
task 8 iter 7400 loss: 9634.7861328125 tv_loss: 0.22757947444915771 norm_loss: 0.8541160821914673 task_loss: 0.0017964644357562065 loss_bn: 0.08912209421396255
task 8 iter 7500 loss: 9642.8515625 tv_loss: 0.2274695634841919 norm_loss: 0.854112982749939 task_loss: 0.0017869668081402779 loss_bn: 0.09002785384654999
task 8 iter 7600 loss: 9645.6044921875 tv_loss: 0.22734735906124115 norm_loss: 0.8541098833084106 task_loss: 0.0017799813067540526 loss_bn: 0.0903773233294487
task 8 iter 7700 loss: 9632.2919921875 tv_loss: 0.2272462546825409 norm_loss: 0.8541094064712524 task_loss: 0.0017721656477078795 loss_bn: 0.08912564069032669
task 8 iter 7800 loss: 9621.8486328125 tv_loss: 0.2271486520767212 norm_loss: 0.8541067838668823 task_loss: 0.001762250903993845 loss_bn: 0.08818410336971283
task 8 iter 7900 loss: 9612.3896484375 tv_loss: 0.2270563244819641 norm_loss: 0.8541059494018555 task_loss: 0.0017543052090331912 loss_bn: 0.08731938898563385
task 8 iter 8000 loss: 9598.958984375 tv_loss: 0.22696630656719208 norm_loss: 0.8541043400764465 task_loss: 0.001746947062201798 loss_bn: 0.08605244755744934
task 8 iter 8100 loss: 9596.046875 tv_loss: 0.2268710434436798 norm_loss: 0.8541026711463928 task_loss: 0.0017397404881194234 loss_bn: 0.08583594858646393
task 8 iter 8200 loss: 9734.3603515625 tv_loss: 0.22677385807037354 norm_loss: 0.8540979623794556 task_loss: 0.0017352212453261018 loss_bn: 0.09971816092729568
task 8 iter 8300 loss: 9611.49609375 tv_loss: 0.22665515542030334 norm_loss: 0.8540938496589661 task_loss: 0.0017194657120853662 loss_bn: 0.08759449422359467
task 8 iter 8400 loss: 9577.2783203125 tv_loss: 0.2265322059392929 norm_loss: 0.854088306427002 task_loss: 0.0017071871552616358 loss_bn: 0.08430232852697372
task 8 iter 8500 loss: 9556.453125 tv_loss: 0.22642381489276886 norm_loss: 0.8540857434272766 task_loss: 0.0016958733322098851 loss_bn: 0.08233661204576492
task 8 iter 8600 loss: 9708.7802734375 tv_loss: 0.22629570960998535 norm_loss: 0.8540757894515991 task_loss: 0.001691961893811822 loss_bn: 0.09761964529752731
task 8 iter 8700 loss: 9665.59375 tv_loss: 0.22620528936386108 norm_loss: 0.854077160358429 task_loss: 0.001679282751865685 loss_bn: 0.0934273824095726
task 8 iter 8800 loss: 9643.9921875 tv_loss: 0.2260822057723999 norm_loss: 0.8540699481964111 task_loss: 0.0016734243836253881 loss_bn: 0.0913342759013176
task 8 iter 8900 loss: 9632.337890625 tv_loss: 0.2259853631258011 norm_loss: 0.8540658950805664 task_loss: 0.0016644931165501475 loss_bn: 0.09026308357715607
task 8 iter 9000 loss: 9618.4296875 tv_loss: 0.22588986158370972 norm_loss: 0.8540618419647217 task_loss: 0.0016563513781875372 loss_bn: 0.08895877748727798
task 8 iter 9100 loss: 9609.1767578125 tv_loss: 0.22578907012939453 norm_loss: 0.8540569543838501 task_loss: 0.0016497204778715968 loss_bn: 0.08810564130544662
task 8 iter 9200 loss: 9606.7294921875 tv_loss: 0.2256930023431778 norm_loss: 0.8540520668029785 task_loss: 0.0016430921386927366 loss_bn: 0.0879329964518547
task 8 iter 9300 loss: 9599.50390625 tv_loss: 0.22560396790504456 norm_loss: 0.8540477752685547 task_loss: 0.0016368292272090912 loss_bn: 0.08727827668190002
task 8 iter 9400 loss: 9592.904296875 tv_loss: 0.22551646828651428 norm_loss: 0.8540438413619995 task_loss: 0.0016310850623995066 loss_bn: 0.08668054640293121
task 8 iter 9500 loss: 9571.404296875 tv_loss: 0.22543764114379883 norm_loss: 0.854041337966919 task_loss: 0.0016248056199401617 loss_bn: 0.08459672331809998
task 8 iter 9600 loss: 9611.646484375 tv_loss: 0.22532838582992554 norm_loss: 0.8540319204330444 task_loss: 0.0016210090834647417 loss_bn: 0.08866935968399048
task 8 iter 9700 loss: 9565.3759765625 tv_loss: 0.22526565194129944 norm_loss: 0.8540317416191101 task_loss: 0.0016112850280478597 loss_bn: 0.08414030820131302
task 8 iter 9800 loss: 9582.7646484375 tv_loss: 0.22518296539783478 norm_loss: 0.8540309071540833 task_loss: 0.00159963290207088 loss_bn: 0.08599749952554703
task 8 iter 9900 loss: 9577.8671875 tv_loss: 0.22509653866291046 norm_loss: 0.8540260791778564 task_loss: 0.0015911298105493188 loss_bn: 0.08559829741716385
task 8 iter 10000 loss: 9576.0322265625 tv_loss: 0.2250162959098816 norm_loss: 0.8540226221084595 task_loss: 0.0015843719011172652 loss_bn: 0.08548669517040253

--- RUN END (단계 2/4: 수행) exit_code=0 ---
